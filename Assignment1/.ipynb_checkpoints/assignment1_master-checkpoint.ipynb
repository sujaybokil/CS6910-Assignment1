{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-piece",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px; text-align:center\">Assignment 1</p>\n",
    "<p style=\"font-size:18px; text-align:center\">CS6910: Fundamentals of Deep Learning</p>\n",
    "<p>Sujay Bokil: ME17B120<br>\n",
    "Avyay Rao: ME17B130</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closed-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "import wandb\n",
    "from sklearn.datasets import make_classification\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl \n",
    "mpl.rcParams['figure.facecolor'] = \"white\"\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-tunisia",
   "metadata": {},
   "source": [
    "# Outline of the Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module to create template classes for Autodifferentiable losses/activations/layers\n",
    "\"\"\"\n",
    "\n",
    "class AutoDiffFunction():\n",
    "    \"\"\"Format for any function in general which has to be auto-differentiable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwds) -> None:\n",
    "        self.saved_for_backward = {}\n",
    "        self.grad = {}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "\n",
    "        output = self.forward(*args, **kwds)\n",
    "        self.grad = self.compute_grad(*args, **kwds)\n",
    "        return output\n",
    "\n",
    "    def forward(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def compute_grad(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def backward(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Layer(AutoDiffFunction):\n",
    "    \"\"\"Format to create your own custom layer for the model\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwds) -> None:\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.weights = {}\n",
    "        self.optimizer = None\n",
    "\n",
    "    def initialize_weights(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        self.optimizer.step(self)\n",
    "\n",
    "\n",
    "class Loss(AutoDiffFunction):\n",
    "    \"\"\"Format to create a custom loss function\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        pass \n",
    "\n",
    "    def backward(self):\n",
    "        return self.grad[\"x\"]\n",
    "\n",
    "    def compute_grad(self, y_true, y_pred):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Optimizer():\n",
    "    \"\"\"Format to create a custom optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwds):\n",
    "        self.remember = {}\n",
    "        pass\n",
    "\n",
    "    def add_params(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def step(self, layer):\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-charles",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "For this assignment we implement the following activation functions:\n",
    "\n",
    "1. Sigmoid activation\n",
    "\n",
    "$$y = \\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{-e^{-x}}{(1 + e^{-x})^2} = \\sigma(x)(1 - \\sigma(x))$$\n",
    "\n",
    "2. ReLU activation\n",
    "\n",
    "$$y = ReLU(x) = max(0, x)$$\n",
    "\n",
    "$$ \\frac{dy}{dx} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & x\\geq 0\\\\\n",
    "      0 & x\\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "3. Tanh activation\n",
    "$$y = tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "$$\\frac{dy}{dx} = \\frac{4}{(e^x + e^{-x})^2} = 1 - (tanh(x))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interested-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(AutoDiffFunction):\n",
    "    \"\"\" \n",
    "    Represents the Sigmoid Activation function\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = 1/(1 + np.exp(-x))\n",
    "        return self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        y = self.saved_for_backward\n",
    "\n",
    "        return {\"x\": y*(1-y)}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]      \n",
    "\n",
    "\n",
    "class RelU(AutoDiffFunction):\n",
    "    \"\"\" \n",
    "    Represents the RelU Activation function\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = np.where(x>0.0, 1.0, 0.0)\n",
    "\n",
    "        return x * self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        return {\"x\": self.saved_for_backward}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]\n",
    "    \n",
    "class Tanh(AutoDiffFunction):\n",
    "    \"\"\" \n",
    "    Represents the Tanh Activation function\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "        return self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        y = self.saved_for_backward\n",
    "\n",
    "        return {\"x\": 1 - y**2}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]\n",
    "    \n",
    "class Softmax(AutoDiffFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        v = np.exp(x)\n",
    "        self.saved_for_backward = v\n",
    "\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-taiwan",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "For this assignment, we only use fully connected OR Dense layers where each input neuron is connected to each output neuron, along with a bias unit. Below is a representation of a fully connected layer.\n",
    "\n",
    "![Representation of a fully connected layer](FullyConnectedLayer.png)\n",
    "\n",
    "The equation for such a layer is simply\n",
    "\n",
    "$$y = FullyConnected(x) = wx + b$$\n",
    "\n",
    "$$\\frac{dy}{dw} = x^T \\quad\\frac{dy}{dx} = w^T  \\quad\\frac{dy}{db} = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "announced-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(Layer):\n",
    "    def __init__(self, in_dim, out_dim, weight_decay=None, init_method=\"random\") -> None:\n",
    "        super().__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.init_method = init_method\n",
    "        self.initialize_weights(in_dim, out_dim)\n",
    "\n",
    "    def initialize_weights(self, in_dim, out_dim):\n",
    "        \n",
    "        if self.init_method == \"random\":\n",
    "            scaling_factor = 1/np.sqrt(in_dim)\n",
    "            self.weights[\"w\"] = np.random.randn(in_dim, out_dim) * scaling_factor\n",
    "            self.weights[\"b\"] = np.random.randn(1, out_dim) * scaling_factor\n",
    "        elif self.init_method == \"xavier\":\n",
    "            lim = np.sqrt(6 / (in_dim + out_dim))\n",
    "            self.weights[\"w\"] = np.random.uniform(low=-lim, high=lim, size=(in_dim, out_dim))\n",
    "            self.weights[\"b\"] = np.random.uniform(low=-lim, high=lim, size=(1, out_dim))\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        \n",
    "        gradients = {}\n",
    "\n",
    "        # y = x * w + b        \n",
    "        # we compute gradients wrt w and x \n",
    "        # gradient wrt b is not required explicitly since we know that it's value is 1\n",
    "        gradients[\"w\"] = self.saved_for_backward[\"x\"].T\n",
    "        gradients[\"x\"] = self.weights[\"w\"].T\n",
    "\n",
    "        return gradients\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x @ self.weights[\"w\"] + self.weights[\"b\"]\n",
    "        self.saved_for_backward[\"x\"] = x\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, dy):\n",
    "        \n",
    "        # calculating gradients wrt input to pass on to previous layer for backprop\n",
    "        dx = dy @ self.grad[\"x\"]\n",
    "        \n",
    "        # calculating gradients wrt weights\n",
    "        dw = self.grad[\"w\"] @ dy\n",
    "        db = np.sum(dy, axis=0, keepdims=True)\n",
    "\n",
    "        # accomodating for weight_decay / regularization\n",
    "        if self.weight_decay:\n",
    "            dw = dw + 2 * self.weight_decay * self.weights[\"w\"]\n",
    "            db = db + 2 * self.weight_decay * self.weights[\"b\"]\n",
    "\n",
    "        self.absolute_gradients = {\"w\": dw, \"b\": db}\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def update_weights(self):\n",
    "        self.optimizer.step(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-penny",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "The loss function dictates how good the output of the neural network is. Since we use MNIST dataset, our job is classification and hence we use the Categorical CrossEntropy loss function. We also have created the Mean Squared Error loss function to check how it performs for a classification task for which it's not meant. \n",
    "\n",
    "#### 1) CrossEntropy Loss\n",
    "\n",
    "$$L(p, y) = \\Sigma_{i=1}^{N} \\Sigma_{k=1}^{K} y_{ik} \\log p_{ik}$$ \n",
    "\n",
    "where $$y_{ik} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & x \\in class-k\\\\\n",
    "      0 & else \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "$p_{ik} =$ probability that $i^{th}$ sample falls in $k^{th}$ class\n",
    "\n",
    "In our implementation, the given loss function is applied along with the activation function for the last layer i.e. Softmax activation. It's formula is given by the following equation\n",
    "\n",
    "$ f: [x_1, x_2, ... x_k] \\rightarrow [p_1, p_2, ... p_k]$ such that $p_i = \\frac{e^{x_i}}{\\Sigma_{k=1}^{K} e^{x_i}}$\n",
    "\n",
    "Now, to find the derivative of loss w.r.t input we have apply the chain rule. Let $p(x)$ represent the softmax activation and $L$ represent the loss. Then the expression turns out to be:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x} = \\frac{\\partial L(p, y)}{\\partial p} \\frac{\\partial p(x)}{\\partial x} = p - y$$\n",
    "\n",
    "#### 2) Mean Squared Loss OR L2 Loss\n",
    "\n",
    "$$L(p, y) = \\frac{1}{2b}\\Sigma_{i=1}^{b} \\Sigma_{k=1}^{K} (p_{ik} - y_{ik})^2$$\n",
    "\n",
    "where $$y_{ik} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & x \\in class-k\\\\\n",
    "      0 & else \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "$p_{ik} =$ probability that $i^{th}$ sample falls in $k^{th}$ class\n",
    "\n",
    "As above, the MSE loss is applied along with Softmax activation on the last layer. The combined derivative of MSE loss and softmax is given by:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_i^{(L)}} = \\frac{\\partial L(p, y)}{\\partial p} \\frac{\\partial p(a_i^{(L)})}{\\partial a_i^{(L)}} = \\Sigma_{j=1}^{K} p_j(p_j - y_j)[\\delta_{ij} - p_i]$$\n",
    "\n",
    "where $$\\delta_{ij} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & i=j\\\\\n",
    "      0 & else \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "As can be seen from the expression, unlike for Cross Entropy loss the expression cannot be vectorised and individual components have to be separately calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coupled-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossFromLogits(Loss):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        v = np.exp(x)\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def encode(self, y): \n",
    "        encoded_y = np.zeros(shape=(len(y), self.n_classes))\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "\n",
    "        return encoded_y\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "         \n",
    "        probabilities = self.softmax(y_pred)\n",
    "        y_true_encoded = self.encode(y_true)\n",
    "\n",
    "        loss_value = np.mean(np.sum(- y_true_encoded * np.log(probabilities), axis=1))\n",
    "\n",
    "        self.saved_for_backward[\"probabilities\"] = probabilities\n",
    "        self.saved_for_backward[\"y_true\"] = y_true_encoded\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def compute_grad(self, y_pred, y_true):\n",
    "\n",
    "        return {\"x\": self.saved_for_backward[\"probabilities\"] - self.saved_for_backward[\"y_true\"]}        \n",
    "\n",
    "\n",
    "class MSELossFromLogits(Loss):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        v = np.exp(x)\n",
    "\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def encode(self, y): \n",
    "        encoded_y = np.zeros(shape=(len(y), self.n_classes))\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "\n",
    "        return encoded_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def indicator(i, j):\n",
    "        ind = {True: 1, False: 0}\n",
    "        return ind[i==j]\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "         \n",
    "        probabilities = self.softmax(y_pred)\n",
    "        y_true_encoded = self.encode(y_true)\n",
    "\n",
    "        loss_value = np.mean(np.sum((probabilities - y_true_encoded)**2, axis=1))\n",
    "\n",
    "        self.saved_for_backward[\"probabilities\"] = probabilities\n",
    "        self.saved_for_backward[\"y_true\"] = y_true_encoded\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def compute_grad(self, y_pred, y_true):\n",
    "\n",
    "        probs = self.saved_for_backward[\"probabilities\"]\n",
    "        labels = self.saved_for_backward[\"y_true\"]\n",
    "        grad = np.zeros(shape=(len(y_true), self.n_classes))\n",
    "        \n",
    "        for point_counter in range(len(y_true)):\n",
    "            res = 0\n",
    "            for i in range(self.n_classes):\n",
    "                for j in range(self.n_classes):\n",
    "                    \n",
    "                    res = probs[point_counter, j] * (probs[point_counter, j] - labels[point_counter, j]) * (self.indicator(i,j) - probs[point_counter, i])\n",
    "                \n",
    "                grad[point_counter, i] = res\n",
    "        \n",
    "        return {\"x\": grad}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-compression",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Optimizers basically denote how to make use of the gradients achieved through backpropogation to update the weights of the model. Based on the question, we have created the following 6 optimizers.\n",
    "\n",
    "1) sgd<br>\n",
    "2) momentum based gradient descent<br>\n",
    "3) nesterov accelerated gradient descent<br>\n",
    "4) rmsprop<br>\n",
    "5) adam<br>\n",
    "6) nadam<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pleasant-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, lr=1e-2):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, layer):\n",
    "\n",
    "        for weight_name, _ in layer.weights.items():\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - self.lr * layer.absolute_gradients[weight_name]\n",
    "            \n",
    "class Momentum(Optimizer):\n",
    "    def __init__(self, lr=1e-3, gamma=0.9):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #Momentum update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            self.remember[weight_name][\"v\"] = self.gamma * self.remember[weight_name][\"v\"] + \\\n",
    "                                                self.lr * layer.absolute_gradients[weight_name]\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - self.remember[weight_name][\"v\"]\n",
    "\n",
    "class NAG(Optimizer):\n",
    "    def __init__(self, lr=1e-3, gamma=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma \n",
    "\n",
    "    def step(self, layer):\n",
    "\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] + (self.gamma**2) * self.remember[weight_name][\"v\"] - \\\n",
    "                                            (1 + self.gamma) * self.lr * layer.absolute_gradients[weight_name]\n",
    "\n",
    "            self.remember[weight_name][\"v\"] = self.remember[weight_name][\"v\"] * self.gamma - \\\n",
    "                                                self.lr * layer.absolute_gradients[weight_name]\n",
    "\n",
    "class RMSprop(Optimizer):\n",
    "    def __init__(self, lr=1e-3, beta=0.9, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #RMSprop update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            self.remember[weight_name][\"v\"] = self.beta * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta) * (layer.absolute_gradients[weight_name] ** 2)\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - (self.lr / (np.sqrt(self.remember[weight_name][\"v\"] + \\\n",
    "                                                self.epsilon))) * layer.weights[weight_name]\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "                self.remember[weight_name][\"m\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #Adam update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            \n",
    "            #Update m_t and v_t\n",
    "            self.remember[weight_name][\"m\"] = self.beta_1 * self.remember[weight_name][\"m\"] + \\\n",
    "                                                (1 -self.beta_1) * layer.absolute_gradients[weight_name]\n",
    "            \n",
    "            self.remember[weight_name][\"v\"] = self.beta_2 * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta_2) * (layer.absolute_gradients[weight_name]**2)\n",
    "            \n",
    "            #Bias correction\n",
    "            m_hat = self.remember[weight_name][\"m\"]/(1 - self.beta_1 ** self.t)\n",
    "            v_hat = self.remember[weight_name][\"v\"]/(1 - self.beta_2 ** self.t)\n",
    "            \n",
    "            #Update parameters\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - (self.lr / (np.sqrt(v_hat + self.epsilon))) * m_hat\n",
    "            \n",
    "        self.t += 1\n",
    "            \n",
    "class Nadam(Optimizer):\n",
    "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1\n",
    "\n",
    "    def step(self, layer):\n",
    "        \n",
    "        # we have 2 parameters to remember m(t) and v(t) for all weights in the layer\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "                self.remember[weight_name][\"m\"] = np.zeros_like(weight)\n",
    "\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            \n",
    "            self.remember[weight_name][\"m\"] = self.beta_1 * self.remember[weight_name][\"m\"] + \\\n",
    "                                                (1 -self.beta_1) * layer.absolute_gradients[weight_name]\n",
    "\n",
    "            self.remember[weight_name][\"v\"] = self.beta_2 * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta_2) * layer.absolute_gradients[weight_name]**2\n",
    "\n",
    "            # bias correction step \n",
    "            m_hat = self.remember[weight_name][\"m\"]/(1 - self.beta_1 ** self.t)\n",
    "            v_hat = self.remember[weight_name][\"v\"]/(1 - self.beta_2 ** self.t)\n",
    "\n",
    "            d = self.lr / (np.sqrt(v_hat) + self.epsilon) * (self.beta_1*m_hat + (1-self.beta_1)/\n",
    "                                                (1-self.beta_1 ** self.t) * layer.absolute_gradients[weight_name]) \n",
    "\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - d\n",
    "\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-cleveland",
   "metadata": {},
   "source": [
    "## Framework for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "enclosed-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, layers) -> None:\n",
    "        self.layers = layers\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.forward(*args, **kwds)\n",
    "\n",
    "    def compile(self, loss, optimizer):\n",
    "        self.loss = loss\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Layer):\n",
    "                layer.optimizer = deepcopy(optimizer)\n",
    "\n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        gradient = self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient)\n",
    "\n",
    "        return gradient\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                layer.update_weights()\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy_score(y_pred, y_true):\n",
    "\n",
    "        pred_labels = np.argmax(y_pred, axis=1)\n",
    "        return np.sum(pred_labels == y_true) / len(y_true)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_batches(X, y, batch_size=32):\n",
    "        batches = []\n",
    "\n",
    "        for i in range(len(y) // batch_size):\n",
    "            start_idx = batch_size * i\n",
    "            end_idx = batch_size * (i + 1)\n",
    "\n",
    "            batches.append([X[start_idx: end_idx], y[start_idx: end_idx]])\n",
    "\n",
    "        # take care of the last batch which might have batch_size less than the specified one\n",
    "        if len(y) % batch_size != 0:\n",
    "            batches.append([X[end_idx:], y[end_idx:]])\n",
    "\n",
    "        return batches\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val, batch_size=32, epochs=10):\n",
    "\n",
    "        # calculate number of classes to pass to the loss function\n",
    "        self.loss.n_classes = len(np.unique(y_train))\n",
    "\n",
    "        train_batches = self.create_batches(X_train, y_train, batch_size=batch_size)\n",
    "        val_batches = self.create_batches(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        num_train_batches = len(train_batches)\n",
    "        num_val_batches = len(val_batches)\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            total_train_loss = 0\n",
    "            total_train_accuracy = 0\n",
    "\n",
    "            ## TRAINING ##\n",
    "            for X, y in train_batches:\n",
    "\n",
    "                preds = self(X)\n",
    "                total_train_loss += self.loss(preds, y)\n",
    "                total_train_accuracy += self.accuracy_score(preds, y)\n",
    "\n",
    "                _ = self.backward()\n",
    "                self.update_weights()\n",
    "\n",
    "            train_loss_per_epoch = total_train_loss / num_train_batches\n",
    "            train_accuracy = total_train_accuracy / num_train_batches\n",
    "\n",
    "            total_val_loss = 0\n",
    "            total_val_accuracy = 0\n",
    "\n",
    "            ## VALIDATION ##\n",
    "            for X_v, y_v in val_batches:\n",
    "                val_preds = self(X_v)\n",
    "                total_val_loss += self.loss(val_preds, y_v)\n",
    "                total_val_accuracy += self.accuracy_score(val_preds, y_v)\n",
    "            \n",
    "            val_loss_per_epoch = total_val_loss / num_val_batches\n",
    "            val_accuracy = total_val_accuracy / num_val_batches\n",
    "            \n",
    "            print(\"Epoch: {} Train Loss: {:0.6f} Train Accuracy: {:0.6f} Val Loss: {:0.6f} Val Accuracy: {:0.6f}\".format(epoch, train_loss_per_epoch, train_accuracy, val_loss_per_epoch, val_accuracy))\n",
    "\n",
    "            self.history.append({\"Epoch\" : epoch, \n",
    "                                    \"Train Loss\": train_loss_per_epoch,\n",
    "                                    \"Train Accuracy\": train_accuracy,\n",
    "                                    \"Val Loss\": val_loss_per_epoch,\n",
    "                                    \"Val Accuracy\": val_accuracy})\n",
    "            \n",
    "            wandb.log({\"epoch\" : epoch, \n",
    "                        \"train_loss\": train_loss_per_epoch,\n",
    "                        \"train_acc\": train_accuracy,\n",
    "                        \"val_loss\": val_loss_per_epoch,\n",
    "                        \"val_acc\": val_accuracy})\n",
    "\n",
    "        print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularizing the Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    if name == \"relu\":\n",
    "        return RelU()\n",
    "    elif name == \"tanh\":\n",
    "        return Tanh()\n",
    "    elif name == \"sigmoid\":\n",
    "        return Sigmoid()\n",
    "\n",
    "def get_optimizer(name, lr):\n",
    "    if name == \"sgd\":\n",
    "        return SGD(lr=lr)\n",
    "    elif name == \"momentum\":\n",
    "        return Momentum(lr=lr)\n",
    "    elif name == \"rmsprop\":\n",
    "        return RMSprop(lr=lr)\n",
    "    elif name == \"adam\":\n",
    "        return Adam(lr=lr)\n",
    "    elif name == \"nadam\":\n",
    "        return Nadam(lr=lr)\n",
    "\n",
    "def create_layers(n_layers, layer_size, activation, weight_decay, init_method):\n",
    "\n",
    "    layers = []\n",
    "    layers.extend([FC(784,layer_size, weight_decay, init_method), get_activation(activation)])\n",
    "    \n",
    "    for _ in range(n_layers):\n",
    "        layers.extend([FC(layer_size, layer_size, weight_decay, init_method), get_activation(activation)])\n",
    "    \n",
    "    layers.append(FC(layer_size, 10, weight_decay, init_method))\n",
    "\n",
    "    return layers\n",
    "\n",
    "#Function used for WandB sweep\n",
    "def train():\n",
    "\n",
    "    config_defaults = {\n",
    "        'n_layers': 3,\n",
    "        'layer_size': 32,\n",
    "        'weight_decay': 0,\n",
    "        'lr': 1e-3,\n",
    "        'optimizer': 'sgd',\n",
    "        'batch_size': 32,\n",
    "        'init_method': 'random',\n",
    "        'activation': 'relu',\n",
    "        'epochs': 5\n",
    "    }\n",
    "\n",
    "    wandb.init(config=config_defaults, magic=True)\n",
    "\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "    train_images = flatten(train_images / 255.0)\n",
    "    test_images = flatten(test_images / 255.0)   \n",
    "\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, shuffle=True)\n",
    "\n",
    "    model = NeuralNet(create_layers(wandb.config.n_layers, \n",
    "                                    wandb.config.layer_size, \n",
    "                                    wandb.config.activation, \n",
    "                                    wandb.config.weight_decay,\n",
    "                                    wandb.config.init_method))\n",
    "\n",
    "    \n",
    "    model.compile(loss=CrossEntropyLossFromLogits(), optimizer=get_optimizer(wandb.config.optimizer, wandb.config.lr))\n",
    "    \n",
    "    model.fit(train_images, train_labels, val_images, val_labels, batch_size=wandb.config.batch_size, epochs=wandb.config.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60000 Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(f\"Train samples: {train_images.shape[0]} Test samples: {test_images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAFuCAYAAADwJes0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XeYVOXZP/DvtO29so1duogUAUUEEWxRAqjgK803ICRYUkSiEUsES4gmsSTRxKBGsQTia2IP1tijwCLEUKSXZXfZZdldtszs1Of3hz8mnrkf3GHZcs7y/VyX1+W5OXPmmZl7njlnZ+77sSmlFIiIiIiIiMg07F09ACIiIiIiIjLihRoREREREZHJ8EKNiIiIiIjIZHihRkREREREZDK8UCMiIiIiIjIZXqgRERERERGZDC/U2snYsWPx9NNPa/9t9+7dSEpK6twBERGdRPbu3QubzYZAIAAAGD9+PJ544okuHhUREVHbndQXaklJSeH/7HY74uPjw9vPP/98u91P79690dTU9K37HOtC76OPPsK4ceMQCARgs9mwd+/edhsXdW+dld9E7a2kpCScr7m5ubj66qtbnUOJrOBobicnJyMtLQ1nn302HnvsMYRCoa4eGtFx+8tf/oKRI0ciKSkJeXl5uOSSS/DJJ5+c0DH5Rzajk/pCrampKfxfz5498dprr4W3Z8+e3SljCIVC3zpB/+Mf/8DEiRM7ZSzUvRxvfh/9JqIrmWEMZA5H8/WLL77AunXrcO+993b1kFoVDAa7eghkAa+99hoaGxuxb98+LF68GPfffz/mz5+v3Zc5RWb14IMPYuHChbjttttQVVWF/fv34/rrr8crr7zS1UPrVk7qC7Xj5Xa7MWvWLGRmZiItLQ1nnnkmampqwv++Z88enH322UhOTsbFF1+M2tpaAMDOnTths9nC+40dOxY///nPMXr0aCQmJmLmzJn47LPPcO211yIpKQkLFy4M73v0Qm3cuHEAgEGDBiEpKQl/+9vfAACPPfYY+vbti8zMTFx22WWorKwEgPA3cL///e/Rq1cvZGVlYfHixfyrHYXdcccdmD59OmbOnInk5GQ899xzaGlpwU9+8hPk5eWhoKAAixYtgs/nAwA88cQTGD9+fPj2kd/yvv766xg4cCCSk5NRWFiIhx56KLzvq6++iqFDhyItLQ1jx47Fpk2bwv9WWFiIX//61xg8eDASEhI65bGTdRQUFOCSSy7Bpk2bUFJSgnfffTf8b0uXLsVVV13V6jFCoRDuvfdeFBcXIycnB9/73vdw5MgRAMDFF1+MRx55xLD/0KFD8fe//x0A8NVXX+HCCy9ERkYGBgwYgBdeeCG839y5c3Hddddh4sSJSExMxPvvv98eD5lOEqmpqZgyZQr++te/YsWKFdi0aZM2p7xeL2666Sb07NkTubm5uPbaa+HxeAAANTU1mDRpEtLS0pCRkYFzzjkn/Dl///33o6CgAMnJyRgwYADee++9rny41I0cOXIEd955Jx599FFMnToViYmJcLlcmDx5Mn7961/D6/Vi4cKFyM/PR35+PhYuXAiv1wsAqKurw6RJk5CdnY309HRMmjQJBw4cAADcfvvt+Pjjj/GjH/0ISUlJ+NGPftSVD9McFCmllCouLlbvvPPOt+7zyCOPqEsvvVS53W4VCATUunXrVGNjo1JKqTFjxqi+ffuq7du3q+bmZjV27Fh1++23K6WU2rFjh/rmUz1mzBhVXFystmzZonw+n/L7/WrMmDHqqaeeMtxfWVmZKioqUkop5ff7FQC1Z8+e8L+/9dZbKjs7W23YsEF5PB513XXXqQkTJhj2P//881Vtba3as2eP6tOnj7gPOjno8vv2229XLpdLvfrqqyoYDCq3261uvfVWNXr0aFVdXa2qqqrUmWeeqZYuXaqUUurxxx9X5557bvj2kTmZlZWlPv30U6WUUocPH1br169XSim1du1alZOTo9auXasCgYB68sknVe/evZXX61VKKVVQUKCGDx+uysrKlNvt7uBngqzgm/m6f/9+deqpp6o77rhD5PGSJUvU7NmzlVJK7dmzRwFQfr9fKaXUueeeqx5//HGllFJPPvmk6tOnj9q1a5dqbGxUl19+ubrqqquUUkqtWLFCnX322eFjbt68WaWmpqqWlhbV1NSkCgsL1Z///Gfl9/vV+vXrVWZmptq0aZNSSqk5c+aolJQU9cknn6hgMKg8Hk/HPzlkacc61ygqKlJ/+MMftDl1ww03qMmTJ6vDhw+rhoYGNWnSJLV48WKllFKLFy9W11xzjfL5fMrn86mPPvpIhUIh9dVXX6nCwkJVXl6ulPr6/bFz585OfazUfa1evVo5HI7wfBvp5z//uRo1apSqqqpS1dXVavTo0eqOO+5QSilVU1OjXnzxRdXc3KwaGhrUFVdcoS699NLwbb85d5NS/EbtOLhcLtTU1GDnzp1wOBzh3+UeNX/+fPTr1w8JCQn4n//5H2zcuPGYx5o3bx4GDhwIl8sFp9Op3eeNN97AJZdccsxjPP/88/j+97+PYcOGIS4uDvfddx8+/PDD8F8mAGDx4sVIT09HSUkJfvKTn2DlypVteOTUXY0dOxaTJ08O17A9//zzWLp0KbKzs5GTk4M777wTzz77bFTHcrlc2LJlCxobG5GRkYHhw4cDAJYvX47rr78eZ5xxBhwOB+bNmwcAWLduXfi2N9xwAwoLCxEfH9/+D5Is6bLLLgt/A3vuuefitttua/Oxnn/+eSxatAi9e/dGUlISfvnLX2LVqlUIBAK4/PLLsXHjRuzbty+879SpUxEbG4vXX38dJSUluPrqq+F0OjF8+HBMmzYNL774YvjYl156KcaMGQO73Y64uLgTftx0csrPzw//CuebORUbG4vHH38cDz30EDIyMpCcnIzbbrsNq1atAvD1vFtZWYl9+/bB5XLhnHPOgc1mg8PhgNfrxZYtW+D3+1FSUoI+ffp05UOkbuTw4cPIyso65vnr888/jzvvvBM5OTnIzs7GkiVLwucSmZmZmDZtGhISEpCcnIzbb78dH374YWcO31J4oXYMwWDQ0IyhoqICc+fOxQUXXIArr7wSBQUFWLx4saGmpkePHuH/T0hI+Nbi96KiolbH0Fp9WkVFBYqLi8PbKSkpSE9PR3l5ufZ+iouLUVFR0er90skjMg8rKysNOVVcXGzIp2/z0ksv4dVXX0XPnj0xfvx4rFmzBgCwb98+3H///UhLSwv/V1lZecw8JQKAl19+GfX19di3bx/+8Ic/nNBFfORcWVxcjEAggKqqKiQnJ+O73/1u+MR31apV4RrOffv2Yc2aNYbcff7553Hw4MHwsZi71B7Ky8uRkZEBwJhThw4dgtvtxogRI8I5ePHFF+PQoUMAgJtvvhl9+/bFRRddhN69e+O+++4DAPTt2xcPP/wwli5dipycHMyYMYOf/9RuMjMzUVNTc8y6ct2cezT/3G43rrnmGhQXFyMlJQXjxo1DfX096zGPgRdqx+BwOAzNGPLz8xETE4OlS5di69at+OSTT/DSSy+1uXveN2vWdNterxeffvopLrjgAu2/A1//Be7oX4EBoLGxEXV1dSgoKAjHysrKwv+/f/9+5Ofnt2m81D1F5lVeXp4hp/bv3x/Op8TERLjd7vC/ffNkFQBGjRqFV199FdXV1Zg0aRJmzJgB4OuTjiVLlqC+vj78n9vtxpVXXnnMcRDptJaDxxI5V+7fvx9OpxO5ubkAgJkzZ2LlypX47LPP4PF4MGHCBABf5+65555ryN2mpib88Y9/DB+LuUsnat26dSgvL8fYsWMBGHMqKysL8fHx2Lx5czgHjxw5Ev5DcHJyMh544AHs3r0br732Gh588MFwLdqsWbPwySefYN++fbDZbLjllls6/8FRtzR69GjExcXh5Zdf1v67bs49ev75wAMPYNu2bVizZg0aGhrw0UcfAQCUUgA4p0bihdpx+Oc//4lNmzYhFAohJSUFLpcLDoejXY6dm5uL3bt3h7c//PBDDB8+HImJiQC+vnDMzMw07DNz5kw8+eST+PLLL+H1enHrrbfinHPOQWFhYXifX/3qV6ivr8f+/fvxu9/9DtOnT2+X8VL3NHPmTNx9992oqanBoUOHcM8994SbNQwdOhRffvkl/vOf/8Dj8eCuu+4K387j8eAvf/kLGhoa4HK5kJycHH5vLFiwAI8++ijWrVsHpRSamprw2muvobm5uUseI1nXsGHDsGrVKvj9fpSWlhp+gvhtZs6ciYceegh79uxBU1MTbrvtNkyfPj38s52JEydi3759uPPOOzF9+nTY7V9/NE6aNAnbt2/Hs88+C7/fD7/fj3Xr1mHr1q0d9hjp5NHQ0IDXX38dM2bMwFVXXYXBgweLfex2O37wgx/gxhtvRHV1NYCvv3176623AHzdxGnnzp1QSiElJQUOhwMOhwPbtm3DP//5T3i9XsTFxSE+Pr7dzleIUlNTcffdd+OHP/whXn75Zbjdbvj9fqxevRo/+9nPMHPmTNx77704dOgQampqcPfdd4fPJRobGxEfH4+0tDTU1tYaziUAeT58suOF2nGoqKjA1KlTkZKSgkGDBuGCCy7AzJkz2+XYCxcuxMqVK5GWloZFixZpf/Z41113YdasWUhLS8Pf//53XHzxxbjzzjtx+eWXIy8vD/v37xff8E2ePBnDhg3D6aefjssvvxxz585tl/FS97RkyRIMHToUgwcPxpAhQzBq1CjceuutAIBTTz0Vt912G8aPH48BAwaEO5EetWLFivBPGZ588snw79FHjRqFP/7xj7juuuuQnp6O/v3747nnnuv0x0bWd88992DXrl1IT0/HkiVLMGvWrKhuN2/ePPzv//4vxo0bh169eiEuLg6///3vw/8eGxuLqVOn4t133zUcMzk5GW+//TZWrVqF/Px89OjRA7fccku4exlRW0yePBnJyckoKirCL37xCyxatAhPPfXUMfe///770bdvX5x11llISUnBBRdcgG3btgEAduzYgQsuuABJSUkYPXo0rr/+eowfPx5erxeLFy9GVlYWevTogerqaixbtqyzHiKdBBYtWoQHH3wQ9957L7Kzs1FUVIRHHnkEl112Ge644w6MHDkSQ4YMweDBgzF8+HDccccdAL4+3/V4PMjKysJZZ52Fiy++2HDcG264AS+++CLS09Pxk5/8pCsemqnY1NHvGslU+vfvj9dffx39+/dv0+0DgQBcLhf27NmDkpKS9h0cERERERF1KH6jZkItLS2YP39+my/SiIiIiIjI2viNWjfFb9SIiIiIiKyLF2pEREREREQmw58+EhERERERmYx+SfEovfnmm7jhhhsQDAbx/e9/H4sXL/7W/WNssYhD4oncZddKlAuuOot8Iuapj5P7uY1fXNpCmi8yNaFAgryWtqXKBQYDPvlSxlUYO5OpYyxMaAYxmXbU1NR06n0eT/5aKXdVcoKI+TI1OwblWiU23XqTEXmpopw17PKtgVCCTHKnU95pnMNv2PZ/FYruTruA2XMXsFb+AoAtxiVi/tQYw3ZcZovYxxeU7cf9LfJYurkWDhlMS3CLWL3b+P6KK5PjUCHz5mukFjTDpzq3i2V3mXtt8cbPel+KzD9nil/E/Jo8ddbKz3pHkzG3QgmxYh9fmhxXRpJc+sQfkvfZXC/PaVwHrbNsCufejmfTLOkQSpR5GIiX5xPivFfzA76QS+a93a+ZP5s83zZMS4o2f9v808dgMIj+/fvjnXfeQWFhIc444wysXLkSp5566jFvk2LLwCjb+W25u+joFslrz192ninXOEl/qFzENr12iojlfGE8a3V45cmpzSeTs2aoPOl2TDosYof3povYKffsMWwHq6rFPmZRN3wPSktLO+3+jjd/Ozx325H/ghEitvd/5fvAVhsjYs4m+R6yByIWY8/UXM0pebvEA3ICbh4sT2pzshpErH+6MVerRst9zMLsuQu0c/529DwLwFlcJGKVEwsN2/2v2ib2KWuUZ62VO7JFzO6VjyGYKvP60uEbROyVjcMM26cslOMINTaKWNQ64fn9pjXqPTSo2g47fqTuNPfaTzN+1ldcmCH2Sb+kQsQq61JELGeVvGhK/ninYbtleC+xz56pcp6dfdZnIlbllff52d+HiljB/f8SMbM66ebeE2HXrKEX0v1l1siRLs8tPWf2EbHDp8nzieyNxj8AOVrk/TUVyi82EivkH47sH8u5WCty/jRxdVe0+dvmnz6uXbsWffv2Re/evRETE4MZM2bglVdeaevhiDoV85esirlLVsb8Jati7lJXaPOFWnl5OYqK/vtXz8LCQpSXy2+Xli9fjpEjR2LkyJHwg4uEkjlEk7/MXTIjzr1kZZx7yao491JXaPOFmu4XkzbNTzYWLFiA0tJSlJaWwgX5u1airhBN/jJ3yYw495KVce4lq+LcS12hzc1ECgsLUVZWFt4+cOAA8vPz22VQQrS/2Y/yt6jB8cNFbNd041Nx14S/i31alKzxKnEdErGca1aL2LDY9nuzPnmkh4j5e8vfH//g8jLD9qdeeV1+3YbZIlbwoCy+t3268XiGaHqdmr+drHyC/K342P6bRSygKS6/LPsLEesTkeMjYuXxv/TJ2rOvfLkittVTIGKbG/NE7NJMY74tR2+xz8mq03O3jb/5dxbK13rrzwpFbMqY9SKW7twlYlU+Yx4mO2XO/bLwVRHrNSTpW8d5VFNIHu8fbpnDgSHG9032J7IebWuTnKNLP+8vYgN+vUfEAgervnWcVmeFubdh1lkiVnDdThGr8xqbzRS76uWxvLIG5/TCAyL24wfeFbExccbP7L81yTqz5pCcjz8+MkDE9jdp6tgnbRexc79XZ9h+aN0FYp9+c+V79mRghdw9pijq0WwjTxMxb6o8d60bIHOucZDsHhZzJKIBVJ3sw+BNk+f3gTj5nkm1ny5i9g81dWsmrklrqzZ/o3bGGWdgx44d2LNnD3w+H1atWoUpU6a059iIOgzzl6yKuUtWxvwlq2LuUldo8zdqTqcTjzzyCL7zne8gGAxi3rx5GDRoUHuOjajDMH/Jqpi7ZGXMX7Iq5i51hRNaR23ixImYOHFie42FqFMxf8mqmLtkZcxfsirmLnW2Nv/0kYiIiIiIiDrGCX2j1mmiLA50ZGWKmGelLCS/rvhvIhZjMxZa7vVliX2qfbKQd1OzLJgPKNmkId5uLLTsFy8Lxg/45GKZfs2xQprFhXUWt+QYtrNcTWKfmwe9I2JpT7tFbMnmySLW47KtUY2DOlcgQb5f1pYVi1heulxE+p06WUz8gd343nhSc59pTpkzdpscx85mufjw3iMy79Pymg3bjkGyOD64WS40TF3DPnSgiE1c+YmIZR6RjTd2N8m51hOQDY38QeNc2OyTBe0vbpYF5wmJsj12MCj/RunzyY9Dl0sW4PfMMDZb2O+UTRqSnPI+zz/n3yJ26Az5+VS1YrSIZT4pFzCm9qHL3eYrj4jY+q1ysWl7QsCwbbPLOU+F5Of1/oA8V7m9eeq3jhMAAiGZt0HN+UBtQ6LcT5PzoYCMbVjf17DtypNz+/blZ4hY/wXrRIzMLTL3G0tk3iTvlHO2u4ecex2xcq5MPGjMr8Tth+UYTpXvhbhqOX96M2RTE+f5I2Tsve7X6IbfqBEREREREZkML9SIiIiIiIhMhhdqREREREREJmONGrUopbwifx8+I/NTEVvT2EfEImvB4h1+sY8nKOsmdHU4MbZAq/t92Vwk9nHaWl+QEABcUe4XqdqXLGI1flkjoauBu2fQKyL26JnT5J2s/U+bxkbtJ7VPnYj1zagRsfx4WYdRECtvmx+xiOu6JlmrEWuXOZ+qqVvzJ8iaS6dNLoKZbDcuPlx+gfwdew+5hjd1hChqhOt+KefLz+rlPLunQdYjxjll7ujmIG9EjZpNM/fq6tG8XvkxF9DUozk19WjJCXIR7Mj6OW9QHku3yLHDLuffRJdcJLbvPFl72fB3WQcXrJPvVTp+22+Wr1WoRs5TOpE1abGx8n0QCMhj+TW1Yfv2y1pNe4Mxt0Jxcq60aWrgVIzcT0tzWziNjylYliB2yR4oa42OXCUXCU997vPoxkFdwpdpfG0TyuV8Z/PIOSqxXObN/075UMRGjTYuEj+/dI7YJ/5DOX8mb6gUMVeZnO89A3JFzJ5snGdDjbLGzmr4jRoREREREZHJ8EKNiIiIiIjIZHihRkREREREZDK8UCMiIiIiIjIZyzYTCZwnF7qbmCkbXnzRXCJiCXZZHBkLY0F7ToxcDPjCRLnAc75DFji6bPL6tzFkPH6CXRYYe5UsANZdSSfb5WKD7pAsYt4dML68qxuHyNsF5bGgqS9uUbKRyvbvyyLs/mvlbalz9U6Xhd5F8bLxQEFsvYgNiKsQsX+7jYtl6xqH6Brc5LvkfYaUzOgMZ7OIxUUcz5cmdqEu4uxdImKDM2Xxd1mzfNESXHKe8gbkx1BGnGxEkx1vzDtdE5qAJr98mmYfvpCcf9NiPCKWFycb7nhDxrlQ12TKG5L3WeWRzUR0TUdy42Tx+7ZZQ0Us59F/iRgdv+JnZC4c+bH8/K87LF8/VW18/dxJmlMqTeMQHZtP0xQky3iuovloBhpk/tla2v43eHvEOIIpcm4/VC7f2/3ZOMQ8NOeX9iEDRMyfYtyverhcVDq5LF7GyuU5wFWpspFcYyii2U6MvJ07T55DV59XKGJNRTL7W3rJ5lExE04zbPdZUS32CW7fJWJmxm/UiIiIiIiITIYXakRERERERCbDCzUiIiIiIiKT4YUaERERERGRyZxQM5GSkhIkJyfD4XDA6XSitLS0vcbVqgPnySYYmc4mEUt3yqJ0v5KFlnF2Y5F7jV8WDs/4w09FLLFCFrQn75MFjk1FxiLNpHK5j7LLYkm7Tx4/GCvHH1kUCgDVpxtf3rtnPi/2Wd/cS8R0zVb8SqbKQxNWitgf0VfEzKor87cj9UqUzURKD/cUsTXBEhH7XnGLiJ0WX2bYPhRIiWocMZoGIzqVvlQRc8BYYBwYIN/HJ7OuzN1Ajnz9x6TKxhb/DJ0iYilOOe/la5rauENyfo9sOqObx+2aBiO6Rje6pjaxdtnoxAF5vMi5UHefkQ1HAACat83GRlk0n+KUTU1axssGI3hUhqzCTHOv62153+6zzhaxM7/zlYit3dDPsG1zysYI9gT5eRqqlU0bIpt4AICqMb4PHF65TzBe3qfSjMPZKHPenymbO4Qi/n5vT5D7DFi4X45DRLonM+XusegahzT2kee0rmbj3JW+U77WNYPluV/uWrnfx548EZuWZGzKc88g2fDvli/mitjhkTKb4g/I+T77Q/k5ETndHzwvR+yTka855/jgCxEzixPu+vj+++8jKyurPcZC1OmYv2RVzF2yMuYvWRVzlzoTf/pIRERERERkMid0oWaz2XDRRRdhxIgRWL58uXaf5cuXY+TIkRg5ciT8kD97IeoqreUvc5fMinMvWRnnXrIqzr3U2U7op4+ffvop8vPzUV1djQsvvBCnnHIKxo0bZ9hnwYIFWLBgAQAgxZZxIndH1K5ay1/mLpkV516yMs69ZFWce6mzndCFWn5+PgAgJycHl19+OdauXSsStqNMumSNiDWHZIFuZJMQAPAG5MPOchqLtXd4csU++b+SBfON088Ssaoz5UrueQ8Yb1u+WBYrZ/1HjtWfJYvSlUMWFCcclAXLxUvWGrZbpstj6RqHZLlk4XqFP03ErkvbLGKPjbjUONb1ch+z6Mr8bU/2hATDdklcmdjntbrTRCwQkMW5KyDzuSjZ2OzhvAxZVF/iOiRi27z5IqZrHLK1voeIfZrQx3j8XNkg5WTWlbl76PREEYuzybnr7NRdIqZr7OGyaQrYNQ1rPqk15sS/98tGHI79cSLmbJbzpUPzR25Xs6YRhHxYCMYaj1c/SI7/hnPfFrFqn3xM/ROrRaxnTI2IfRzxfrA6s8+9Pe+Wn/WXzd4nYv/OLTBstxyWn/1Bt5xnnW75YyZnk8zTSNomIc3yWJreXwi5NPndJMcWSjHmc/bb8j0VrDl552Oz5y4A+DJlHiZUyEZhvoyIZhwyRdBzdYOIOWpl474/zb1cxNKefc6wrfucKHqnWcTsAdmgKeSUed6SI8/5XY3Gz5hQjLxdU4GmWVV6uogF6+pErCu0+aePzc3NaGxsDP//22+/jdNOkyeDRGbE/CWrYu6SlTF/yaqYu9QV2vyNWlVVFS6//Osr6EAggFmzZuHiiy9ut4ERdSTmL1kVc5esjPlLVsXcpa7Q5gu13r1749///nd7joWo0zB/yaqYu2RlzF+yKuYudQW25yciIiIiIjKZE17wuqvcmvOxiL3e3EvEYjXV4OkuWagYqXe8bI6wCZki9vGDfxCx8qBbxM7tf6Nhe89kebtx/5HFmO8M+quIJdhlIeSSQ4NE7POhxuYhbk2zlcKYWhFrUbLpiD8kU+WV5gIRqzzH2Cyix3qxC7Uze48cw/Z+r8w/b60sLo7N8IhYkks2l+kRZywm9itZgJ7jkMXFd+w9U8SCIVkwHwjK49X4kw3bdl2VM3WJ7D9+JmLPvDtBxHZeLRsyxQ48ImIFy+Trr9b9R3PPxjm5L+Qc7UiRDTtsyUny+Iny/RBK0TSCiJdzobPR2Ikk59EtYp/VkM2XRmyQnztjE7eLWHlAFrVfkL9NxNbz76ztwuaSn6fKL+fBZy85V974/taP79A0DtH01EEwXs5xDo9xvtRMvdrb2b1ynlXRpkvEfmnPyPc7mYc9OVnEgrHyxbYHNA1smo2JGEiQCebpkSBiMZp50bW9XMSS7cYGJnfuuUzebs9BEWse0VPEbAGZ58reep6HnJomPZpQqK9sToV1Fm8mQkRERERERB2DF2pEREREREQmwws1IiIiIiIik+GFGhERERERkclYopmIGjNMxNZ4vxKxZk2zDJemale3OnoPl7HIfYO7OKqxTZw2V8TsHnn8nkXG6sWJd14k9km2ySYQV3i/I+9UU0BZf0F/eTx8btj+qE7uMz5DFqnrmkXoYocCsoi1ZXREU4mHxS7UzgI5xgYKjYE4uZOmf05MTEDEmvyysD7Wbtzv1UHCAbXkAAAgAElEQVRZYp9BO2Uh8dk99ojYxxW9RczTIguT93iM9+EJyH1k6wfqDNsfk01idL1e8j6UQdtG2ezDly7zcMbWahFzRCTxrpYcsc+WBpkV5Y2ymYg3oGlgouSbxGZrEbHcZOMcN79wn9jnxeoRIvbF92VzlY1H+shxVFSJWMgtPxuofegah+gEdu+VsT2jDdsxxc1ynxbZjMHRpOtmIEMOb0RA89nvlHeJlkxNgxFNAxPdn+pjD8i5lszLli/nFV2zDIdbzrPBBOMlQNwhOd8F4+RlQiBRxlxZsgnSj5b+xLAdf1hzPt5TNjVTNk2ee+VtlaZRiD2i6UhTppzrHT75/nAXyM+O+HUi1CX4jRoREREREZHJ8EKNiIiIiIjIZHihRkREREREZDKWqFGrujnyh9pAD0eDiO1Ftoh5Q/L31rkuuehqdcBYO+EOylqdwPnDRcyTLY/vyZDXv5HDaO4haxM0a3PD2SJ/SxuMkb/L9abJWMu1xt/Pn530odin2i9rRvrHVYqYQ1OEkuqQP46fM3CNYftDVhJ1uGC88W180CNrB3VinfI337kJjSK2+UieMaBkfmz2ysXPa32yNmNMnqxb294ga408QeMbJkGzEDeXwO4aBe/KuaZCrneNmktl7cGvRv5NxH76xlUi9swdk0XMm2qcVxvkFIpAoiYrdCGnZvFUl6amzicfa3Mo1bD96xdmiH1iGuWx6m7R1C/55cLYoXr5flh83msi9sp5Q4zHqpQLx1LHUnbj65yaJHP+cEjOg8FYmR+uRplrkecNdnkqBHt0JXbaRbZ14qs1BU5kWqEE2ZvBn6BZ8DpVntPGHDbWpAWT5D62kGYh9haZTLYmWUd7ZKJxbL5PZb1w4nZ5O3uGrLPXLVyti0Uu2u3Ok/tkb5An28155q2D5zdqREREREREJsMLNSIiIiIiIpPhhRoREREREZHJ8EKNiIiIiIjIZFptJjJv3jy8/vrryMnJwaZNmwAAtbW1mD59Ovbu3YuSkhK88MILSE+Xi921l8Baeez7sy4Rsek5cnW6fjFy4dQih1xZ8qkjpxm2vSH51PzjmcdEzK9kUaVfs3BqS0QsziavkRPsspjRrrmW9ipZCOmyyUX9dvuN+/25dozYpyC2TsR0C4K7bHKxxA/rTxGxT98yFrgX419in85khvztcBG1vnVeWbyu47DLPK1oShWxGcWlhu3VkA0Qtjbni1iVWzaq+by6l4idmi+bIKS5jEX5lZpjWaIT0gkwa+6Ou/0zEWsKyoL29TVFIvbnirEi9r0JH4nYkiu3tDqOppBcnLU2JOepFiWLyYOamFvJjIrTdGBIjVg5uNApC+Q3+2RTidv3XSZiO2rk4vFxX8pC+kd2y9vmVXbt3Noas+ZvVOzy8xQhmQsJlcbPZ8cgzarVmj+HO7yahh2apjehGGPQ0aLJZZkucGr20zUi8WXI8SaVt951xOaSTSeiXTjcCqyUu35N442YRvm6+lI1i1Q3GJPT7pXzZyg+uk9alShbbyR8aJwbU/Zrjp8ox+/0yP0CmnE4vJpme3HG3HfKXiVweOXzE9C8j6BZeBuq89uYtfqN2ty5c/Hmm28aYvfddx/OP/987NixA+effz7uu+++Dhsg0Ylg/pJVMXfJypi/ZFXMXTKTVi/Uxo0bh4yMDEPslVdewZw5cwAAc+bMwcsvv9wxoyM6QcxfsirmLlkZ85esirlLZtKmXw9VVVUhL+/rtZXy8vJQXS1/XnjU8uXLsXz5cgCAH5rv3ok6WbT5y9wls+HcS1bGuZesinMvdZUObyayYMEClJaWorS0FC7IOgYis2LukpUxf8mqmLtkZcxfak9t+kYtNzcXlZWVyMvLQ2VlJXJyctp7XAaFy2TR9JFlcr8/9xgtYp4hsqD94AJZhL50yGuG7c1NsjnCA4dPE7EdbvnYEx2yqDbWLht0tJXdJosZXZqi98P+RMN23wT5F6AVO88SsZxLv4pyJE0i0tXNQ6LR2fnb4SLqXYOh6P7+otsvMUbmbklMTURENhP58EAfEbuqr2zu89ju8SJW40kUsZKkw4Ztf1AW93f3ZiI6Zsjd/3tbNiUaMXabiN3c520Ru2nt/4jYrjd7i9gz2eNELPGAMV+Vrt+DJimC8XK+1N1WxxaQxeTOiD4huqndL/uLoKVIvrd2XrJcxK7OHy9izxTLhisXrJ9n2HZ88IW8U5MxQ/62p5S9EZ+7ms/mUIymsYOcQpFYJudje0T+eTPk8WPqZY5qen9Bc1oCZZfHa8dTlW7FDLnrSJFNtZrTomuycaSXnPRcTcaLyNjD8twYmv44Nk3nm1CsbIYX02jcTzvvOmT+hhzyvRByavI8JMfhjzfetiVT3qUtKG8XSNTM9QXyOiBwoFwesIO16Ru1KVOmYMWKFQCAFStW4NJLL23XQRF1JOYvWRVzl6yM+UtWxdylrtLqhdrMmTMxevRobNu2DYWFhXjyySexePFivPPOO+jXrx/eeecdLF68uDPGSnTcmL9kVcxdsjLmL1kVc5fMpNVfD61cuVIbf++999p9METtjflLVsXcJStj/pJVMXfJTDq8mQgREREREREdn25Vjx84WCViLk2swHO6iMX92VhBG4rs0AAgVbPEeV7sERGLtctKXn8U1esOm6zatGuKNnXHynI1ilhDwLhSfLZT7uNdmyFiZDERKeLTNN5wuOXfZJpbYkSsT3pk4xCg3J/e6hA8O1NFrPDUWhGzeeU4KmvkbZFt3HQ5ZLMc6hrxA+pFrK4lQcQ+bugvYonr4kXMM6pZxL7bb4uIhZQxd6Jt0KSbLyOPBQB23fyraQ4ROb8HNE15vqiVTawaXpSF6feeIRtUrS0rFrHBB2eJWNEXOw3bfId0PlezMWdalDxv0NI0aNCkJIIRDQM1KYrYOpmjLVlyHH7Zs0krGBvlY6BOp5Sm+YumMYY/SSaTP1kez9nStlkj5JLHd4ZkckacgsLliS63/ClyzlY2eVuHTz72+n7GsXnz5OdEKEYz/mbN81iUJWI2qzQTISIiIiIioo7DCzUiIiIiIiKT4YUaERERERGRyfBCjYiIiIiIyGSs20xEU1hoj40VsVCLZqV1TUHmbp9xlfmYKBuCBKO81o1sFBLUVQ63s2iK7TW9ULRsTpkqKqgpRNU8t9S5QpqCdqV5p/u8LhFLdPhEbJu7R0RE5lXaV5qBTJEhR4ZXxGyahg2b6/MM27rHRF1jXMFuEYvX5M3FqV+K2GcHzxSxBo/MQ09QNropdxubzjjtsnjdG5CJrmtEo2sAojQ5psvNrDhj8xN3QI5/UNpBEVvnls1EesVWi9ipPeRt+yTJJj+bSgYYA182iH2ojULRNVmw+405WH04Re7jk7kWUx/d539sRN8ev1/maGTDBgCIr5Z568mWt3U26ZqcaTqWkCnYYuW86GySuRp0aRpvyI9euA4aG8z5e2g6jmjSIaQ5vrLLnHZFNOhwuuXBQrFyzrZrmoSE5DSrFUgw3tZVq/lMqJVzZTBOXj8EE+Rtu+Kiid+oERERERERmQwv1IiIiIiIiEyGF2pEREREREQmY90aNU0tVMir+RGuhmvTHhHb6c41bMc7ZB1OXSC6FSN1i2VHLlwd7TKDukWwdbVyurElOVt/PmIaoqwpc2h+yx6QdXzUBSLSLcElc/dQnOaH5praCb+mdrLCE7kgtayXyfnkkIi5bpH5YXfIcaiQfL8ku4y1pbUtUa7WSh3OaZezV61Pvj4tShYVxDTI27riZb4GNHkYE3G/MQ5NfkWu/g79eAM2OZ/pFrwOaOZaV8Txklzydrr64IRD0c2XpyRXydtqagDdPY31UHGyJJDayq75vNPUrXnTjKdQaal1Yp9atzzN8mbI11P3aW2rMdYkhRJkrjlS5LFCPl3tmYZdvl8ae8YZtnUzr/LL+6SOZ0tOEjHllHOlprQW3nQZVPERNW+68kTN1zl2v+YOHJo68oiQJ1NTL9Yo50VHi+a8N1HeNhAvBxc53fuy5fE9BTKr4w7LxxSIl+8j1qgRERERERERL9SIiIiIiIjMhhdqREREREREJsMLNSIiIiIiIpNptS5u3rx5eP3115GTk4NNmzYBAJYuXYrHH38c2dnZAIBly5Zh4sSJHTvSKNg0DS+UpuFFsKFJxBoimnGkuTxiH7dmEVZdkbeuoD2ywYiuSYjudi6bZjFDm7y+rgskiFhejHE1a7umUtQW7N4LVFspf9sqFFHEq1ukFw4ZS0qTOe7Q3Hb9jhLDdn9NMxHU1H77IP8/3XrougYjkU7GBa/Nmru6OcmuyRu/ZpX12JoWEYuLl3O0P6Qp4o6oEo82J3T76Rs+SR7NYtZ+l3FsusZTusW44w40ilhNQC6Q7A1pnje7fI58KcYRx4k9upZZ8zcqUS54nXDQ2AKkamum2CelXLNIdYLMK6d8a8CTY3xf2TVNQmL2y89+3eLGfs1axvEH5fvWnd+9zwmiYdbc9fdIE7FgrGZ+0zT2cMqPe8EW0C1ILXPOFpI5YmtpvVmSpkcUHB45fwZj5eLTmlNmaE7JEVtrfOzBOM11geacw6lpYNLQU87FXTHPtvqN2ty5c/Hmm2+K+I033oiNGzdi48aN5pxoicD8Jeti7pKVMX/Jqpi7ZCatXqiNGzcOGRkZnTEWonbH/CWrYu6SlTF/yaqYu2Qmba5Re+SRRzBkyBDMmzcPdXVy7ZCjli9fjpEjR2LkyJHwa1cKIep80eQvc5fMiHMvWRnnXrIqzr3UFdp0oXbddddh165d2LhxI/Ly8vDTn/70mPsuWLAApaWlKC0thQvyd6dEnS3a/GXuktlw7iUr49xLVsW5l7pKmxbZzs3NDf//D37wA0yaNKndBnQilKbAUUtTKOyLKOAOaaoedUXpusJ6HX/IWDwcZ5cFlDp2TQWl7j51Y/MrYxFljOZ2ugJNrWifWwswa/62VSjGmKsZsW6xz4Fa+VaP6SGLf1M1TXRiymXhe6TgYdlMxB2SH1BOp6aJjl3mVkvQeJ8evxxDfKuj6n7MmrvaZhdK0xBkf7WIJcclilg0dA1MApp5O84u5z0nNDFNAxBd0ydfRKMT3WPXsbXIv6zr5nfdOHQNRnQNA8zOrPnbVuXnGht5JO2V+6Tu1TSb8Wjyr17mRyDNOIe2ZMh50NWsyVuvPH5TgabzgkZdjvF4zuIiOa59ZfKGdvl+j7YpixWYIXd1jT2CMXIeqO8r50Gl+Zy17as0bPtH9RX7uBpkw7xgfJSXDhF3adc0r9M1IfGlys+EuMPyfVR1pmztEXPEeB9xh+Rz0ZyrmTs1Ia/sDdQl2vSNWmXlf1/cl156Caeddlq7DYioozF/yaqYu2RlzF+yKuYudZVWL4tnzpyJDz74ADU1NSgsLMRdd92FDz74ABs3boTNZkNJSQn+9Kc/dcZYiY4b85esirlLVsb8Jati7pKZtHqhtnLlShGbP39+hwyGqL0xf8mqmLtkZcxfsirmLplJm7s+EhERERERUcdoUzOR7mh8+jbD9hZ3vthHVzQe1BSv65p96IrS25PuPhuDxkJLXeG6pt6fLG5waoWIbXX3E7F4l8znJIcsaE/d1bZx7PFmi1is5j7dLbLIPS3G2NSk1pMg9qGuoWtcpOOIrCQHEDhYJWJxzp5R3UcgoomHbj7zBuVHmlOzX0hTOR4KRvd3y8hGN7rjO6CZaxNl4ft2dw8RS3PKZkA6QXk4aosom2A4BshGC55TWgzbwb2ygZIvTTYA8WbI+0zeLV/QQERPheZiOS7XEZnz/mRdLkfXEMzRZLzt7qtlM5GeSzXNRLpR4xCzsvvkc6wc8vMzFCtf69haOefZ4oz56k/UnM82RDe2YIqmeZjXOA5fkjx+IF22BXO2aJro1ch5sbmnfG85vzK+t3p83iL22XexHGvGZhGC7qPOdsZgud+6/8gd2xG/USMiIiIiIjIZXqgRERERERGZDC/UiIiIiIiITIYXakRERERERCbTvZqJqLY37GhRsigxUqrTI2ItIXk7XeMQuzIWVdo1hb26AnddQb5b0wEkySmbQNT5jQ0YQprGJ0FXdI0BTuS5pY5lCxpzJM9VL/ZpyfeLWLxLxlI1jQzStzS1aVxbG2WjhLwUWZm8ozlHxCLfC9E2sCDrSY2R82pAM1dFNg9x2jVNPKJs2qTNJ01I1ywqFDEXNgVkYbrLLov+g4my6P+DfbJBxaz+pSJ2JCAL7vmWaCdRNsEomyLnqfivjNvBOPl5HaNpxuDuKfM0uVzGak+JOEXTpHdCuUyE+tPkOOKq5emeN0M+9ph6Y8578mUDKNvpg0RMbdB0Y6B2FUiQr2Hk5z8ABGNkTuS/f0TEVMiYUK4mXbOS6L7Psfs1yRkxtFCUVxzOZjkOf5ZsKJa0u/VueDGV8g0YWyffyw6fHL9NM8l6cuVc3NF9nfiNGhERERERkcnwQo2IiIiIiMhkeKFGRERERERkMrxQIyIiIiIiMpnu1UzkBNT4kw3bsXZZQOsOyWLwWJvcz69p9hHZHCHOLhs5HAnKIsWgpsI9wSEbh+gahRwMpYhYJF8aK9JPBvZEmac6uuY1zmpjEXJ0RwI2HcwTsUt6bRGxJp9sxpDo8Bm2vX5OVWZR5kkXsR5xsmDbpZkbdTJjZQObRk2Djsg5LhBlfyNdkya7Tea5rsGTrilIZCMST0A2lNIdS9nlOLwHkkQs4RSfiNUpWUiv+ZihDtQ8SH7uJm425qnuNQ7KVAZidMkrP8OjeY1tIZlrtpAm5+XwEV8gG0UFGo3nDc4GOYjGvjJvkzZ82yipPTi8Mm9iGjVNlbzyNbP7NE1h7G37riYYJ2/nqtWNw5ibwTiZl8462UzKXSLPXXXvhbTd8jE1FhjPFdSBSrFPIDFbxHQNWBIPaD4TmqI9A2o//EaNiIiIiIjIZHihRkREREREZDK8UCMiIiIiIjKZVgs/ysrK8L3vfQ8HDx6E3W7HggULcMMNN6C2thbTp0/H3r17UVJSghdeeAHp6bJ2wSp0dWXR0C2wGoriWC6brH3Q1TXo6OrRIheD1e3XHJI/lg9EuVKf0vwO3gpOlvz9Jl1uxcXLupfMuGYR09VJhg5Wt2kcnhpZVxPsJXO3Z3KdiPVPrDJsb7AXtGkMVmaW3LXHGScJ3WLRupzb6ZULnuskOmXxTHNA1gNH0s2DCU6Z5z7NKqu6GjWdOIesJY48XjCkWRRbUxenXHK/xP0yluRoETFvSNbBhVzmri82S/62hf20U0TMcVDmZGT9mUtOqfpFfgPytQvEt/53c5vmdro13pW2Bk6el7R45GMKZRtrcGIPygfgzpbHklVr1mXa3NWkiO5009UoY7Yjsh5RpRhfNXtAU1vr0OScbj/N/CbmKG1ayuPr5ra4Wjm3B+I0OZ1l3LbFy5PcHmtknZkvSR7L5dHUqNXL+TnKcuk2a3VmcDqdeOCBB7B161Z8/vnnePTRR7Flyxbcd999OP/887Fjxw6cf/75uO+++zp4qETHj/lLVsXcJStj/pJVMXfJTFq9UMvLy8Pw4cMBAMnJyRg4cCDKy8vxyiuvYM6cOQCAOXPm4OWXX+7YkRK1AfOXrIq5S1bG/CWrYu6SmRxXz+u9e/diw4YNGDVqFKqqqpCX93X77by8PFRX638etXz5cixfvhwA4IemPyxRJzne/GXukllw7iUr49xLVsW5l7pa1M1EmpqaMG3aNDz88MNISWl9fa6jFixYgNLSUpSWlsIF3YIiRB2vLfnL3CUz4NxLVsa5l6yKcy+ZQVTfqPn9fkybNg2zZ8/G1KlTAQC5ubmorKxEXl4eKisrkZOT06ED7WiiGD7KOu2gpqA9uvuTxYy6xiTR3qeumD+y6N+tayaSYM0mIcfjZMjfb9K9zna7fJ1zYmXF8X5PhoiFWjSVyVFw1WoWSvXLwt6WoJyGUh3GRZD9wZNzdV8z5K5SxtzRNROJ1zTd+OhwP83RqkQk1i7nQl0zjkAUc639BBa31h0/oMlNp904T+uejxZN8w9fqjxWxjb5vCVqVibWNicxdy8RAObI37Zo7iNPynX9Z1TESxrU9MDRLnitWZBa23Qkcp80+V6xaxZch1PXFEKz2z45H6vexrlXHZID86VqjpUnmwcFKg/KHS3CjLmra+Kha7wR0uRh4EC5jJ0/ok3jcLbI803lkPOnWKDbJpPQny4bmDk98lzYnxTdDwCdEQ19Av0KxT6JX8pFsJu+UyRiDq98bn2ZmvFGNbK2a/WTTymF+fPnY+DAgVi0aFE4PmXKFKxYsQIAsGLFClx66aUdN0qiNmL+klUxd8nKmL9kVcxdMpNWLwQ//fRTPPvssxg8eDCGDRsGAFi2bBkWL16MK6+8Ek8++SR69uyJ//u//+vwwRIdL+YvWRVzl6yM+UtWxdwlM2n1Qm3s2LHipy9Hvffee+0+IKL2xPwlq2LukpUxf8mqmLtkJm0rsCIiIiIiIqIO09E1cJ3rGH8BaYs4uyzyjpau2YeueD1SbJT3qSsst2sakTjtxoLPlsjKZ+gLjMlagvHGfDvgSxf72DSV8D1iGkRsfY0sqE1C25qJJO+TsUSnbJRQ55PFuZH8fiaqWYSibGb0VZUstC/WNBOJphESACQ4fYZtp2bOi3XIZgv+UHS5o5tDdY/VF3E8XbMSnZZUOY7MjfUipms0pf38sEAzEasKOaNr3uLwGLeDmqks5JKvnc0nD6btJRZx05hEn9hF20zEJ/PWky/zKvMLTU6eddiwvbNKPijdWyqUIz93YOFmIlbmaIlyP7cxJ1SMzJuQU8Z0TU1sQZnAtmBEIyrNFYfdK+f/QIJMMF+SjMXWy5yOaYi4z1h5u2D1IRFTDnnuY9NcUzg0jVQ6Gr9RIyIiIiIiMhleqBEREREREZkML9SIiIiIiIhMhhdqREREREREJtO9monYNNW+UTYYaQjEGbYTYmTRbrT8mg4dkc1JWpQsANYV1euOpaMrendEFLl7Q/I+NTfTU7pKZzKDoMuY956gfJ3jXLLoNtXpFrGaI0kiJiPRSaiOrjmDLpYcUQ0dCrFzglnomhlp564DiVEdr96fIGI7a7NErLHJ2NQgFIwuJ1RQM8nZNcXwuqYgmruI/Jhxxcj3VlqMfG/5kzQH27lfhByaxiF+3fume316m4onU/N8x8jXJT6iJ0HdqXKfUJyMORvl8YMxchz2iNRKTfKIfYIx8n1mb5HHLzpVNvZQ/5ANfyobkw3boRg5j6s0+X5XLjZ86gqBWPlap+yXr48jK1PEqoYY596sDU1iH5UgzydCDk2DEc3rrxzGOU/XL8/hkcFAQZyIOb2tNyvR3UcwTo7L4Yvu/D7y/QcAStNoqKPPTviNGhERERERkcnwQo2IiIiIiMhkeKFGRERERERkMrxQIyIiIiIiMhmWIx+DS1NFqGvGYdcUfusK6yNjuoLxoKYkUbefju62urFFirJXCZlYSDQT0VSla2gbQLREMSVE2bTH6ZHFvw2BWBHzhWQS7mzJNWwHvJyquoot4vWOZl4BAFdTdCXWaS7ZeCMhRhaY++KMOVCYVi/28QZlnviCMr+iLf62axqMOOzGvK5pks0c8uIaRGxND02jieZmEUtzyFi8Qz4fmo8jaictWZoM0TSgiT9snENrUjTvDadmbjwoczKoaVYSW2eMNbplk4WEE/hze0yjzKumemODCZumkZNyy/E3F8n3QUJp28dGki9Vvukbi2QC5HzhFbHAgCJ522LjdvZ6mYORDUEAwB7QNJixa5psRDT7SK6Q59UtubKZlObUBM4mGfSlyfne5TbeZ3Ou3CdGc75i0zQO8WRpmqZozq/a2nAtWvxGjYiIiIiIyGR4oUZERERERGQyvFAjIiIiIiIymVYv1MrKyjBhwgQMHDgQgwYNwm9/+1sAwNKlS1FQUIBhw4Zh2LBh+Mc//tHhgyU6HsxdsjLmL1kVc5esjPlLZtJqhb7T6cQDDzyA4cOHo7GxESNGjMCFF14IALjxxhtx0003dfggo6YpEIzW+hpjoWVRYa3Yx60pIvRrunHoYkkOb6v76GJBJa+lvSH5siU4Wu8KojuWckT5nJ3Ac9tVLJW77Wh3Y2ZU+5X70kVMeVpv2mHT5JoKyErc2CrZJKIlKIuhQ0oWIYci2j2olpOv641p8tdlfM2aA3IedIdkTPOyav31zbEiFkiRheOxNcYc2ONIEfvoitB1dE2UtOPVxGwRdfS2gNzp/xqGi1jh+ugG1xzSNdyR70vNdG4apsndNgokaprIeOTr3JIemUhyHnTEyZjdL98vIafm+FkR24fjxT4xiZokzWoRoVPTD4rY2n55IqZCEQ1GNE1UdA1GfMkyIWWbCGswa/4mrN0tYolfJYuYqpHnr8jLEaHefzfmZiApunnc5pfNRHRNxpwtEU30vPJ23nR5ThBzRL5n/MmaplCaKTXGbQx6sjRNAONkU57MJz8TMUdmhoipFtmoRfNstKtWz8ry8vKQl/f1mzk5ORkDBw5EeXl5Bw+L6MQxd8nKmL9kVcxdsjLmL5nJcf1Nbu/evdiwYQNGjRoFAHjkkUcwZMgQzJs3D3V1ddrbLF++HCNHjsTIkSPhh7wSJeoMzF2yMuYvWRVzl6yM+UtdLeoLtaamJkybNg0PP/wwUlJScN1112HXrl3YuHEj8vLy8NOf/lR7uwULFqC0tBSlpaVwQf6kg6ijMXfJypi/ZFXMXbIy5i+ZQVSryPr9fkybNg2zZ8/G1KlTAQC5uf9dkPYHP/gBJk2a1DEj7CRFycbFU4tc8je+CXafiJ0RL38zHKP5xaororAh1R5lMYWGW/Oj4TjNwqyvNQ00bBe45F9/EnrJhVm17JqijlDbH0NnORly151t/HvLGWmVYp9tR3JFLMvZJGI2bxR/u9HVQ2pq1Ow+GUt1ydoJXY1aqsNjvMskzWqUJwEz5K89ybiQrSOySM6eCVoAACAASURBVAvHWDw9Nbpf7vdeLGsDTmYhzd9PdYuM+1PNXTdshtxtK9Vb1teqfbLiKiBLXQTdoulBWWoGh5wakf+p8duY3TM19byas7j0D+TA3rafImKpmuk+IdU493rccjnfxH3yMyDzta0iZv4zhGMzY/4Gaw7LoC6m0TJOvv6RHC3RvWL+ZFn3pRO54LUvVSarPaiZ2zT1aIG46L5X8iUZ70NXj4xTesvYxi0iFDysqfXrAq0+cqUU5s+fj4EDB2LRokXheGXlf08GX3rpJZx22mkdM0KiNmLukpUxf8mqmLtkZcxfMpNWv1H79NNP8eyzz2Lw4MEYNmwYAGDZsmVYuXIlNm7cCJvNhpKSEvzpT3/q8MESHQ/mLlkZ85esirlLVsb8JTNp9UJt7NixUJrW7BMnTuyQARG1F+YuWRnzl6yKuUtWxvwlMzHxSixEREREREQnp6iaiViGZsG9aBdqXrOpj2F7bWwvudMRWUCpXFEudRdxSexo0lwja1cW1Cw2qVlgVbMb7BHrVvo0xefZpVGuSmuBxiEnq+x/G6vQV+ePFPsop3zt/9QrVcQKPozi/RKMLhfU3gMi9vE+WcSbkyqbmpTaiw3bMVs01ffUKQKVxoVyt+86Q+yzs1Iuppq9Lsq/A+rmbZ0o53KrW/TWbBFLL5aNoLI2nhzPR1fo/T3ZGEP5ZTOxyCZb2ZrPSfvQgSKmtsjj2wbIuTG06SvDdv/35BCilflElDsub9vxeYZgHjaXXLha1yjE6THGAvGy84bTrWnkpT3flMcPuYzHi7w/ALBpbufJk5/3CVXy/edPkpcwsUeMg3N5NM2Z6hrlWEUEpmmix2/UiIiIiIiITIYXakRERERERCbDCzUiIiIiIiKT4YUaERERERGRydiUrgdpB8nKykJJSQkOHTqE7OzszrrbDmH1x2C28e/duxc1NTVdPYxjOpq7gPmeu+PF8bcvs+cuwLnXTMw2frPnL+de8zDb+M2euwDnXjMx2/ijzd9OvVA7auTIkSgtLe3su21XVn8MVh9/V7L6c8fxn7y6w3Nn9cdg9fF3Jas/dxz/yas7PHdWfwxWHT9/+khERERERGQyvFAjIiIiIiIyGcfSpUuXdsUdjxgxoivutl1Z/TFYffxdyerPHcd/8uoOz53VH4PVx9+VrP7ccfwnr+7w3Fn9MVhx/F1So0ZERERERETHxp8+EhERERERmQwv1IiIiIiIiEym0y/U3nzzTQwYMAB9+/bFfffd19l3f9zmzZuHnJwcnHbaaeFYbW0tLrzwQvTr1w8XXngh6urqunCE366srAwTJkzAwIEDMWjQIPz2t78FYK3HYBZWy12A+Uv/ZbX8Ze7SUVbLXYD5S/9ltfxl7pqM6kSBQED17t1b7dq1S3m9XjVkyBC1efPmzhzCcfvwww/V+vXr1aBBg8Kxm2++Wf3yl79USin1y1/+Uv3sZz/rquG1qqKiQq1fv14ppVRDQ4Pq16+f2rx5s6UegxlYMXeVYv7S16yYv8xdUsqauasU85e+ZsX8Ze6aS6deqP3rX/9SF110UXh72bJlatmyZZ05hDbZs2ePIWH79++vKioqlFJfJ0T//v27amjHbcqUKertt9+29GPoClbNXaWYv2Td/GXuklVzVynmL1k3f5m75tGpP30sLy9HUVFReLuwsBDl5eWdOYR2UVVVhby8PABAXl4eqquru3hE0dm7dy82bNiAUaNGWfYxdJXukrsA8/dk1F3y16qvO3O37bpL7gLM35NRd8lfq77u3SF3O/VCTWlWArDZbJ05hJNWU1MTpk2bhocffhgpKSldPRzLYe52LebviWH+dh3m7olh7nYt5u+JYf52ne6Su516oVZYWIiysrLw9oEDB5Cfn9+ZQ2gXubm5qKysBABUVlYiJyeni0f07fx+P6ZNm4bZs2dj6tSpAKz3GLpad8ldwHqvPfP3xHWX/LXa687cPXHdJXcB6732zN8T113y12qve3fK3U69UDvjjDOwY8cO7NmzBz6fD6tWrcKUKVM6cwjtYsqUKVixYgUAYMWKFbj00ku7eETHppTC/PnzMXDgQCxatCgct9JjMIPukruAtV575m/76C75a6XXnbnbPrpL7gLWeu2Zv+2ju+SvlV73bpe7nV0U98Ybb6h+/fqp3r17q3vvvbez7/64zZgxQ/Xo0UM5nU5VUFCgnnjiCVVTU6POO+881bdvX3Xeeeepw4cPd/Uwj+njjz9WANTgwYPV0KFD1dChQ9Ubb7xhqcdgFlbLXaWYv/RfVstf5i4dZbXcVYr5S/9ltfxl7pqLTSnND2iJiIiIiIioy3T6gtdERERERET07XihRkREREREZDK8UCMiIiIiIjIZXqgRERERERGZDC/UiIiIiIiITIYXakRERERERCbDCzUiIiIiIiKT4YUaERERERGRyfBCjYiIiIiIyGR4oUZERERERGQyvFAjIiIiIiIyGV6oERERERERmQwv1IiIiIiIiEyGF2pEREREREQmwws1IiIiIiIik+GFGhERERERkcnwQo2IiIiIiMhkeKFGRERERERkMrxQMymbzYadO3e2ut/evXths9kQCAQ6YVR0snn66acxduzYY/77JZdcghUrVnTiiIg6TklJCd59992uHgYRkSl927lptOetkVo7zzjZ8ULtOH3yySc4++yzkZqaioyMDIwZMwbr1q3r6mERnZC25vXq1asxZ86cY/47J2BqK861dLIoKSlBfHw8kpKSkJ6eju9+97soKyvr6mFRNzZ+/Hikp6fD6/V29VA6zAcffIDCwsKuHsYJ44XacWhoaMCkSZPw4x//GLW1tSgvL8eSJUsQGxvb1UMjarOOymt+y0ttZfW5lrlPx+u1115DU1MTKisrkZubix//+MddPSTqpvbu3YuPP/4YNpsNr776alcPh1rBC7XjsH37dgDAzJkz4XA4EB8fj4suughDhgzBrl27cN555yEzMxNZWVmYPXs26uvrw7ctKSnBb37zGwwZMgSpqamYPn06Wlpawv/+61//Gnl5ecjPz8ef//xnw/2+8cYbOP3005GSkoKioiIsXbq0Ux4vnRy+La+Puummm5Ceno5evXph9erV4fj48ePxxBNPAPj627MxY8bgxhtvREZGBqZPn45rr70Wn332GZKSkpCWlta5D4ws69ty8ui3tMfKySNHjmD+/PnIy8tDQUEB7rjjDgSDQQBodZ7+pq+++gq9evXCqlWrAAAVFRWYNm0asrOz0atXL/zud78L77t06VJcccUVuOqqq5CSkoKnn366g54Z6u7i4uJwxRVXYMuWLQBa//x/5plnUFxcjMzMTNxzzz38+S616plnnsFZZ52FuXPnitKFuXPn4oc//CG++93vIjk5GaNGjcKuXbu0x/nkk09QVFSE999/X/yb1+vFTTfdhJ49eyI3NxfXXnstPB7PMceklMKPf/xjpKam4pRTTsF7770X/reKigpMmTIFGRkZ6Nu3Lx5//HHD/SxcuBD5+fnIz8/HwoUL4fV60dzcjEsuuQQVFRVISkpCUlISKioqjvepMgVeqB2H/v37w+FwYM6cOVi9ejXq6urC/6aUwq233oqKigps3boVZWVlYkJ94YUX8Oabb2LPnj348ssvwx/mb775Jn7zm9/gnXfewY4dO8Qkm5iYiGeeeQb19fV444038Mc//hEvv/xyRz9cOkl8W14DwJo1azBgwADU1NTgZz/7GebPnw+llPZYa9asQe/evVFdXY3nnnsOjz32GEaPHo2mpqZjnhATRTqRnJwzZw6cTid27tyJDRs24O233w7/MSGaeRoAvvjiC1x00UX4/e9/jxkzZiAUCmHy5MkYOnQoysvL8d577+Hhhx/GW2+9Fb7NK6+8giuuuAL19fWYPXt2xz051K253W789a9/xVlnnQXg2z//t2zZguuvvx7PP/88KisrceTIEZSXl3fl8MkCnnnmGcyePRuzZ8/GW2+9haqqKsO/r1y5EkuWLEFdXR369u2L22+/XRzjrbfewsyZM/G3v/0NEyZMEP9+yy23YPv27di4cSN27tyJ8vJy3H333ccc09Fzh5qaGtx1112YOnUqamtrAXz9B7vCwkJUVFTgxRdfxG233Ra+kPvFL36Bzz//HBs3bsS///1vrF27Fvfeey8SExOxevVq5Ofno6mpCU1NTcjPzz+Rp63rKDouW7ZsUXPmzFEFBQXK4XCoyZMnq4MHD4r9XnrpJTVs2LDwdnFxsXr22WfD2zfffLO65pprlFJKXX311eqWW24J/9u2bdsUALVjxw7tGG644Qa1cOFCpZRSe/bsUQCU3+9vl8dHJ6dj5fVTTz2l+vTpE96vublZAVCVlZVKKaXOPfdc9fjjjyullHrqqadUUVGR4bhPPfWUGjNmTOc9EOo22pKTBw8eVDExMcrtdof//S9/+YsaP3689j508/Sdd96pCgoK1D//+c9w/PPPPxe5vWzZMjV37lyllFJLlixR55xzTrs8bjr5FBcXq8TERJWamqocDofKy8tTX375pXbfb37+33XXXWrGjBnhf2tublYul0u98847nTJusp6PP/5YOZ1OdejQIaWUUgMGDFAPPvhg+N/nzJmj5s+fH95+44031IABA8LbANSyZctUz549RY4ePW8NhUIqISFB7dy5M/xv//rXv1RJSYl2TE899ZTKy8tToVAoHDvjjDPUM888o/bv36/sdrtqaGgI/9vixYvVnDlzlFJK9e7dW73xxhvhf3vzzTdVcXGxUkqp999/XxUUFET71JgWv1E7TgMHDsTTTz+NAwcOYNOmTaioqMDChQtRXV2NGTNmoKCgACkpKbjqqqtQU1NjuG2PHj3C/5+QkICmpiYAX3+tW1RUFP634uJiw+3WrFmDCRMmIDs7G6mpqXjsscfEsYlOxLHyGpB5CyCcu5G+mcdEJ6ItOblv3z74/X7k5eUhLS0NaWlpuOaaa1BdXQ0AUc3Tjz32GM4++2zDX4n37duHioqK8DHT0tKwbNkyw1+imft0Il5++WXU19fD6/XikUcewbnnnouDBw9+6+d/5LlDQkICMjMzu+ohkAWsWLECF110EbKysgAAs2bNEj9/PNa56lEPP/wwrrzySgwePFh7H4cOHYLb7caIESPC8+XFF1+MQ4cOHXNcBQUFsNls4e3i4mJUVFSgoqICGRkZSE5ONvzb0W+OKyoqDOfMR2/XnfBC7QSccsopmDt3LjZt2oRbb70VNpsNX375JRoaGvDcc88d8+dhkfLy8gwdnvbv32/491mzZmHKlCkoKyvDkSNHcO2110Z9bKLj9c28Pl7fnGh120RtEW1OFhUVITY2FjU1Naivr0d9fT0aGhqwefNmAIhqnn7sscewf/9+3HjjjYbj9urVK3zM+vp6NDY2/r/27jxOqvLMF/hTS1dXL9UbTe8NDXQDTbO00GxGSUTbhUS8gHE0ejWBSCZ3nHvjkoS5MS6ZjMvkmqhjnMjojMREvDEZ5RLRkRBBBRWbTQXEZmloupve9622c//wM2Te+r3YRXV11znN7/vfefqtqreqnvPWOV31PEe2bNlydgxznaLB4XDIypUrxeFwyLvvvvuFn/+5ubly+vTps7ft7++X1tbWWE2dTK6/v19+97vfyY4dOyQnJ0dycnLkF7/4hRw4cEAOHDgQ9v28/PLL8uqrr8rjjz+u/XtmZqYkJCTIwYMHz66XnZ2d5/wHr4hIXV2dshafOnXqbN1ZW1ubdHd3K3/Lz88XEZG8vDw5efIk3E5k7KzJPFE7D59++qk89thjZxfG2tpa2bhxoyxatEi6u7vPNkyoq6uTn/3sZ2Hf7w033CDPP/+8HDp0SPr6+uTBBx9U/t7d3S0ZGRnidrtl9+7d8uKLL0b1edGF7Yvyeriys7Pl9OnT4vV6h31fdOGINCdzc3PlyiuvlLvvvlu6urokGAzKsWPHZMeOHSIiYa3THo9H3njjDXn77bdl3bp1IiKyYMECSUlJkUcffVT6+/slEAjIJ598wssFUNQZhiGbNm2S9vZ2KS0t/cLP/+uvv142b94su3btEq/XK/fffz//iUvn9Oqrr4rD4ZBDhw7J/v37Zf/+/XL48GG59NJL5de//nXY95OXlyfbtm2TJ598Up5++mn4u91ul9tvv13uvPPOs79mqKurU2p6QzU1NcmTTz4pPp9PXn75ZTl8+LAsW7ZMCgsL5eKLL5a/+7u/k4GBAfnoo4/kueeeO1sHfNNNN8lPf/pTaW5ulpaWFvnJT34it9xyi4h8fvzR2toqnZ2d5/MymQ5P1M6Dx+ORDz74QBYuXChJSUmyaNEimTlzpjz22GNy//33y969eyU1NVW++tWvysqVK8O+32uuuUa+973vydKlS6W4uFiWLl2q/P3pp5+W++67Tzwej/zkJz+RG264IdpPjS5gX5TXw7V06VIpKyuTnJycsz+1IBrKcHLy17/+tXi9XpkxY4akp6fL9ddfLw0NDSIiYa/TaWlpsnXrVnn99dflxz/+sTgcDtm8ebPs379fJk2aJJmZmfLtb3/b8gcAZB7XXnutJCcnS0pKivzoRz+SDRs2SFlZ2Rd+/peVlZ1teJObmysej0eysrIscxkLGl0bNmyQb33rWzJhwoSz36jl5OTIHXfcIb/97W/P67IiEyZMkG3btsmjjz56tlnTf/Xoo49KcXGxLFq0SFJSUuSKK66QI0eOnPP+Fi5cKNXV1ZKZmSk/+tGP5Pe///3Zn/Fu3LhRampqJC8vT1asWCEPPvigVFZWiojIvffeKxUVFTJ79myZNWuWzJ07V+69914R+fyXGDfddJNMnjxZ0tLSLPuTSJvBf78QERERWVpPT4+kpaVJdXW1TJo0KdbTIaIo4DdqRERERBa0efNm6evrk97eXrnnnntk1qxZUlRUFOtpEVGU8ESNiIiIyII2bdp0tulCdXW1vPTSS2OmiQIR8aePREREREREpjOsb9TeeOMNmTZtmhQXF8sjjzwSrTkRjQrmL1kVc5esjPlLVsXcpdEW8TdqgUBApk6dKlu3bpWCggKZP3++bNy4UWbMmHHO27hs8eKWpIgnS2OXa5x9VC/ifb75a+bchZ+5uLHjlz/RATFntw9ixgi30bdp5+aEmKOtd0TnEU1mz10Rc+cvxdaA9IrXGBy1xxtLay/FFtdesrJw8xePkMK0e/duKS4ulsmTJ4uIyI033iibNm36woR1S5IstF0e6UPSGNZedGJUH+988zfi3LXjCZIEA5GP0z2E260Gpk+GMa3lqRAbvwNb1fpPnIRYNDmmTIVYe3kGxFI2fqAGhvML7WG8tuEwe+6KcO2lc/vA2Daqjzdqay+NeVx7ycrCzd+If/pYV1cnhYWFZ7cLCgqkrq4Oxq1fv14qKiqkoqJCfDJ6/7Uj+iLh5C9zl8yIay9ZGddesiquvRQLEZ+o6X4xqes0tHbtWqmqqpKqqiqJE16EkcwhnPxl7pIZce0lK+PaS1bFtZdiIeITtYKCAqmtrT27ffr0acnLy4vKpIhGGvOXrIq5S1bG/CWrYu5SLERcozZ//nyprq6WEydOSH5+vrz00kvy4osvRnNuRCNm1PLXCGJsGDVTx18sh5grXm0K4h2MgzEF47EeLfX2LpyGYL2Yx6n+dONPh6bDmDi3H2IBP/4faEnJURzX2wexzyrnKttJqQMwxr0lBWLjnn0PYtGuCYw1rr1kZcxfsirmLsVCxCdqTqdTnnrqKbnqqqskEAjI6tWrpaysLJpzIxoxzF+yKuYuWRnzl6yKuUuxEPGJmojIsmXLZNmyZdGaC9GoYv6SVTF3ycqYv2RVzF0abcO64DURERERERFFH0/UiIiIiIiITGZYP32kc9C0a7U51OYFRkDTuCDci/pq7l9rOBcJDjG4bD7E4rd8CDFbxUx1CnsOjui8TM+m+V9ImE0rPnt6AcSy09og1ngmTdm2u/D+T9aPg1hLShLESsc3QmzXpjnK9tSHsWHHzCrMyf3tBRA70IQdsjrakiFmd6pNWAb6XTAmcUULxE4WXgyxiffvgpjNjvPV9X0hIiIiihV+o0ZERERERGQyPFEjIiIiIiIyGZ6oERERERERmQxr1GJlOHVaUazx6luxEGKtM/FiwANTBiH25fs8ELNLjbJdvzQBxgT78ALHY1VobaKIiKGpUbPPxotIT52GF6k+Wj8eYo549f506WEEsSarpwFrw2pcPoj1FaoXs25ZuwjGNA4ehtjp1jSIeXuw1szmwAkbhjpfw4fzbz6TCrH40m68fycuc4YfL9AdOk43hohiILQu26x1zrr6cd1cwxwHa1K4te3RnEe490UXtgjzxDEuA2LtV02FWMqL70c0D5szDqfl84Z3X+EKp2/EMPYZfqNGRERERERkMjxRIyIiIiIiMhmeqBEREREREZkMT9SIiIiIiIhMhs1EzmU4BbSacZE2Jjjzv/ACvrnvdkKs7jJsrHDLbVuV7Z1tU2DMDwqehdhvmvExt38yDWKnf1gMMfuOfRC7kIVbtHr6aiyozTKw6Yo7Ee9vcFAtlnU4wrtys6Fp4tHciHnkyhhQtn3XYMORnQdLIBaXjHN1JOB+oGt0EvSp/0Oy2cMrhHe58P57r50HscRXPtDcH/9vRWRKYXz2Gl8qV7btXmy84UvBZkbObXsinxdMIvJjBO2wSBsaRXMebBxCYdA2TgvJX3v5DBhz+DvY1Mzej/cf17sAYs5+PNaJe7NKnUO4jUM0xxO656Q7TgjnMXRNzcLFIxMiIiIiIiKT4YkaERERERGRyfBEjYiIiIiIyGSGVaNWVFQkHo9HHA6HOJ1OqaqqGvpGRCbB/CWrYu6SlTF/yaqYuzTaht1M5K233pLMzMxozOXCsmAWhIw4LFz0XtINsc8uckPMk9YOsX975QplO387Fjz+41uzIea7HK8Knzgfi7Dtgz0YCykWDe4/BGPMxCz52zMN35scGxZxpyQOQKzVq+7Guj44oqkHNwI40B6HBfh+r5qX3r44GGOLH/p2n98/Fv/qmonIoHpbewq+PvZ4TWMSA++rtQznkfgKPmTYRccmYZbcJYpEuPlrc9jFkZyixOrWzIRxqVc3qGMOZeN9afosOb+8GGLJtThuMA3XFp9HXVhTj+Lt+sfj7RKaw2vQEfqYjkG8ne45BTU9EAbG4TzisS8Z3Fb3mDqajysJxmkaReHHhwTi1e3BDLyzkvVnNI96Iqy5RRvXXqRrlhHaTKT2qjQYc/PidyC2s3kyxE7G5+D9J+A8nFeo+/PUp+tgjL/mFN5wGE0AHenpaiCAx0OBrq6w7kuHP30kIiIiIiIymWGdqNlsNrnyyitl3rx5sn79eu2Y9evXS0VFhVRUVIhPBofzcERRNVT+MnfJrLj2kpWdz9rrDeKvCIhihWsvjbZh/fRx586dkpeXJ01NTVJZWSnTp0+XJUuWKGPWrl0ra9euFRGRFBteK4ooVobKX+YumRXXXrKy81l7U538iRmZB9deGm3D+kYtLy9PRESysrJkxYoVsnv37qhMimg0MH/Jqpi7ZGXMX7Iq5i6Ntoi/Uevt7ZVgMCgej0d6e3vlzTfflPvuuy+ac4stTWFhuBwpKRDrvKpU2U6qw59zONt6IZb9PBZf+v62FWINZ9IhVnLfe+r9TyyEMX7N83TvwwJdW8V0iJ26Cq8o7wj5lj9/PwwxBbPlb3FRI8QG/bh7up1Y3OpOUJtgDAxgtXbQp6ku1zQT0fTiEJsjpFrdp/n/jqaiXdesJODX3NaveVCXen+6hiMuNxbs2jQV7YOZmmp7CzNb7hKdj/PNX19Ggpy5vkyJdc3SNF+636NsJ3wF15rMpfUQ6x7ERlnuA/h52l2E92f3qetS8wJck1xteLv+8RASfwau7bYB9bbxLZqGYyX9EDPa8TnpbtsxEx/T3q8+pqtT87w1v+ZzX9wCsSlpbRDbcxAbRXiq1c86fzK+jj0zNS+apifESOLae27BgaF/ouy9CBvQXZ+KXTPddh/Edtjxc7zuz3hMG5itPsbJn3tgTHDfxRAb9wnmXMq+Boi1LMmHWPM89bgj+30YIul/OobBMJvhRHyi1tjYKCtWrBAREb/fL9/4xjfk6quvjvTuiEYV85esirlLVsb8Jati7lIsRHyiNnnyZDlw4EA050I0api/ZFXMXbIy5i9ZFXOXYoHt+YmIiIiIiEyGJ2pEREREREQmM6z2/GOZ9irrmquN65qO2NJTIeYcUMe1zEmEMV2XYsOEo1/5F4hdfNdfQ6zkJU31Ygj/ydohx4iIGAXZEItvw+fZl4fzveYGtYHJgbfnwBjbrgv7pwO2+HiItfZiPmQlY+Ftnw+LxGdnqQWv+89gsat/UNNQw47vHzQO0bDFa/YDDbtL02BE0xTECOP/RXEuLHrPT+2E2NEGLDhPKsJxRGQNDq8hnjp1zWnXNCA6s1BtbuXTNC5o7k6CWF+XG2L2S/D+897B9awnT23QccOKd2HMC+9cArHUQlyTAppOTom/V48l+vCjWeyJ2FglMR0bk7W48biktKQOYp9VTVS247EfiHQV42dASQo+pz4/fl45urGpyUCmenxxzfyPYMzx56bg7XBqNBpsmgZgmmPhnhsWKdu3ztgOY4758DO7wIVJ9/W8PfiYt2DsqSNfVrZ7j2Pe25NwrmcW4XFI3XU4N8OHxyLpe9XzBftt2Byuy4tNdOREeB1D+Y0aERERERGRyfBEjYiIiIiIyGR4okZERERERGQyPFEjIiIiIiIyGTYTOYdwG4dob9uDhbxGyClxz5I+GJP3EjaZuOob5RDzyNCNQ4ZjMBsLrr0pWDyatQeLKrd4FyvbOe5BGOPOz9M8anhXaB8L7JMnQCw1AcuiA6FJIyJZid0Qm5GsNhN5v38SjLHZNU1vNDG7HQvmgyFF7jaHZj/QFMKLLcz9gOEu/gAAIABJREFURdNgxOZVn/ulZcdhTOOAB2IOJ+63uR58zcjkdMXqoXSNnIbTBCoOGx8YPmzUEBY7NkyQYHhNeMIV2pTI8GrmGuZnlpn53TZpm66+r5l5LTDOUaCuXb2HM2FM3CRcCyYXNkMsf3oHxGp2TIdYX476+v5HXSnOKwM/A3v78LPeqMWGUomi3r8D70p66pIhljYVn1NmHjb7yHRjw5XPQufQiJ8J7qtbIXa0FV9v3+EUiNkm9UPsprIPle0p8diMoToRX1vBQy0ajnDW3fOw6Idqs4zLkg+Fdbt8wXWr18D1uSOAx6r3z3hN2W6eiscJPgM/J56tvhhiPZpGJA5NI6NFq/cp26syPoQx//iHWRDzzoWQFr9RIyIiIiIiMhmeqBEREREREZkMT9SIiIiIiIhMhjVq5zKM3/YHWvFifQmb1N/qTtoU3n3ZPfj72mAP/q48rPmGe5HCvDiIxbfjOFeHD2IT/l+Xst0/Aec/ODUH53EBXZO4eRH+ln+88yTE7JoaryxNTUFiSOFCUPMbantceBefDq1H+3xghL9b19xO95jaWraQcp7+AOZkUZKmTsKJr+3pDvyd+cQy/G174OARnAfFRqTrr03zv0cDa2m1DxlhPdrp/421DU+ueQZi/zgFaxSGwxjUFCyNQbaASHybmg8l6ViDdbhFvRq0W1OPpqvBLUtrgNhHbfkQ65iCh0uXX7VX2X7945kwJi8PjwcaD2ZBbMGXPoXYnomFyrb9MNajzZ5TA7FPqrBOecEiXN9OdWdALG/2GWW7IYCf11ma13FhHn6GNWbg539GPBaWVfeor0ecDes5gy7Nvs0ateiKck1r6PvamoL5e8afBrFxDjzO8dixtrEoDmtVmwNqzjk0xz5eA2uIHyzbDLGBUjzu0OXmxe56Zfvrh26FMUmCdfbh4jdqREREREREJsMTNSIiIiIiIpPhiRoREREREZHJDHmitnr1asnKypKZM//y2+u2tjaprKyUkpISqayslPb29hGdJFGkmL9kVcxdsjLmL1kVc5fMxGYYX1w9+Pbbb0tycrLceuut8sknn4iIyA9+8APJyMiQdevWySOPPCLt7e3y6KOPDvlgKbYMWWi7PDozt5jQC7HqLsJqc2CBoy0hAWJGPxZVGv4wCubDbCZS/30sjo/rwXHjDuFFmp0daqxzOjZycLfjXHtaXpaqqiqc3zBFK3+jmbt16/D1LboaL/jd48WLol6WHXo5UpFmr1o8+0Y1Xhg06Mf/yegveK25EHBIsw9D0yQkqGsSollZgoOaCwHrepWEXPB61oxTMGR13rsQ+9FH1+Hda+4/YTNeiDXj397TTGRo7XNPmDp3RcbI2hv6Rka58L3pb3C/7JiFa9X/WfqSsn3Gj2tcT8ANsd/VXASxzGtxfw6X3a0+RvXf4/1P+f7QOf2BsU26DGx4MVzRyt/E7EIpvukuJdb/JWw24H5fbVTguhwbDaS48TOrvh3fv4FuXHudTdhYIPWYut2+BO//KyXVENN5q6oMYtm71Jzvycd13I+HCBIsw9fnmYrfQOxbb62GWO5W9VilqwgfcyALGzRMn4fNRKZ58MLVOluOq8/dO4CNW6b9FJvDtCRt5dprYgUh++RfZX4AY+r96RDrDmBSV/djA57PujB2dfZBZdunaRzi0Byc6JqE5MXhyfiAgevApQlq7v+y9RIYsx+X57CPHYb8Rm3JkiWSkaF2Btq0aZPcdtttIiJy2223yauvvjrkAxHFAvOXrIq5S1bG/CWrYu6SmUTUnr+xsVFyc3NFRCQ3N1eamprOOXb9+vWyfv16ERHxyYXRTpjMLdz8Ze6S2XDtJSuLZO3197MHO8Ue116KlRFvJrJ27VqpqqqSqqoqiRP8OQGRWTF3ycqYv2RV/zV3nQl4zUMiM+PaS9EU0Yladna2NDR8fpHIhoYGycrC34kSmRXzl6yKuUtWxvwlq2LuUqxE9NPH5cuXy4YNG2TdunWyYcMGue46LOAnVTjNPnRjjG4soA1tTHJOERbf+xMxdvHX90PsrW3lECt+Xp2vqxsLNJ29YTQ+GUGxzt/eInz+iU4vxLoGsSHBRYk1EPtN92Jl29A09rA7sfhbx2bXjAtpHmJ34BibrmOHhm5uNgfmpdGrFgC77PiauW0+vJ2m0Yld85w6p+LcMjBkOrHO3RERZpOjcNYv20XYkOHYjdg4ZnJFLcS2T3sMYr/pwkR5s0N9jNpeLIa/JusgxH43+18h9j8Ei87DVf+ducr2lLnYcMdsIsnfoFOkP0t9773tuDZ6Z6lraFkyfnb2+7ERQIYHf1qZmtkKscxSbNBx+s9qfrRqmjatznobYnf8/A6cRz/m98Bfqc0MFmSfhjFV/3c2xGw7kyF2phybpiQddUHMn6DOY/rXsOHNlGRs1PLmqekQS4nTNFfJOAKx7e5iZTt4BOcfSMdjCcGPzREzJtfeUJq1WNfkTnes6kjHdfDLaR8r280BXIs7AnjAmebog1i3H/f5tn687fT4BmV7b18RjBnvwiYhuses8WZCrCT+DMT+sVFtFlPoxuZM/suXQEzasYmczpDfqN10002yePFiOXLkiBQUFMhzzz0n69atk61bt0pJSYls3bpV1q1bF9aDEY025i9ZFXOXrIz5S1bF3CUzGfKrmY0bN2rj27Zti/pkiKKN+UtWxdwlK2P+klUxd8lMRryZCBEREREREZ0fnqgRERERERGZTETNRCwv3OJ1k9IVcobTYCSchiYiIm6so5ath2ZALLtccx2RDrWAu6MYOyPl7sCibMF61TErJQeL3NNdWMha250GsXxnB8S6vGqRrUPT7EPXZEPHbtftB2pMt/v4ApH/zyc4qHnzXepjnurCQmVPfj/EdPNPTcCC9rpsTccc0rOHvD9BLOq3u7HQOziAr7tWmGuvI1tdS478n3wY84dLfgWxugA2UdjeVQqxH9QvhViyA6+BNN6lrl9vHS+BMX2Z2KRh2Qvfh1iRvAcx58RCiJ24FWNV33lc2V711dtgjHfpPLz/P++BmJk5+0Sy9qpr2ulrMQcTjqtt0D9rLIIxUxfXQKwsrQFi7z5bAbETWbjwZdylNhZIG8T3/W8ex8YhSY04/+S/roPYtNRGZbvXj63e++bjZ8e4Lbg/PrjxJoglfgmbgkzPVJ/TO4exoc7haoxNvLIGYleP+xhi/3oKG+i449RjE99M/JwbfA8bjAi+dTQcmrVYd2ypO5asXYNr6tLEzcr2rgFcs8c78XjIZ+AxQW58J8Q82fgZE9qcJMOJx5vdgQSIJdo1a71mbnNduM/c+Se1sZNnJh5Ep8RFfozEb9SIiIiIiIhMhidqREREREREJsMTNSIiIiIiIpPhiRoREREREZHJXJjNRCzUOCRc4TYKCRX88kUQG78Pi5Ozf/UJxNpumQ+xMyvUgv8A1laLHNFcjR17lYxZhWlYKK1rWqDTa+AL2jGAhbGhbHZsMKJrvKFvJhJyXzYco+tlEwxi8X0ggAPtLiysD4Y8RFcvFsfruJy4H+QlYxGyP4f/o9LSdIqx2dWYgakUfuMQjd7rF0Ks4b95Ifb6pU8p23sHCmDML5uwIUh/IA5iRYlY7D07+TTEmnwpEDszqMZunbEbxnzQXgSxb1y7A2JXfQObLZwJHIXYP5/6CsRWTFisbDuSsRmFuwMbqUT2SRE7tqAhcT3qGnH/4s0w7vn8i5Xt7j/kwpiD6diUpTp9PMRyT+GrlH59I8Tyk9S1fFkGvp8P7sEmHmlHcSdq+R3Ore1atTGCQ7OOx3+EjZG6JkFIAvG4bhemaNbGoNrIwZPRC2PG7cN1ojp9IsSqljZDrGVbHsSWfv1DZTvLhU0cttqXQIyiyxaHxxfhru2ZH+Oa3RKy9qbZ8djSZcPPf6+mmcjFGXjc2KxpCrK3X01+jwObjo23Y34VxuFnwscDuE9u6S2G2Jqv/UnZ3ri+Esa43tgFsd65ENLi0QoREREREZHJ8ESNiIiIiIjIZHiiRkREREREZDIXZo2axYV7AcJQJx5eDDFfOv4+ePpTXRCr/9sFEHO34m/ec14+omz7p0+AMcOpZxkLMuLxN/92Td1Xajy+ThUu/B14V59av2XXXPA6XLq6stC6Nd0FtQcHsQ5IxxbmxbhtLnWcdwDvvyOItRnJ8fj6eJxY/6er9SDR1u9GWv966r6LIXbHjVhbdGniExB7vXsWxB5vulzZ1tWeLUw5HtbcfAauoUED/28Zp6mfCK3h2d+JtXITktrDmse6o6sgFq+5cLAI1s8d+5m6nj+78hkYs7mjHGKH1qgFwbZPd37xJGMs4LZJ23S1duaXR78C4/wB9f3rmo65nLULa18CcUkQa/gSzsN3CGveTnerF/D9cCrWaSXX4jxqb8J9av7kYxA7sHW6su1PxPtKWIS5FvBhfjs+9kCsYxBrfI63Zyjb/X14ke2Ty3BfSTmK6/jOf8ELhw8Ua56Dw6ds6y543FWIzykOyzKtK6Q+2ObE9c3m0Hy3YsdYcEBT8x7EtSyU4cPPz3A98cxTEKv1pynbZ3xpMCbNgXVrAcFcer8f623ddh/ExjvV49eu4NA1/CIi3UGsg9floe4xfziuWtn+984rwnrMcPEbNSIiIiIiIpPhiRoREREREZHJ8ESNiIiIiIjIZIY8UVu9erVkZWXJzJkzz8YeeOAByc/Pl/LycikvL5ctW7aM6CSJIsX8Jati7pKVMX/Jqpi7ZCZDNhP55je/KXfccYfceuutSvzOO++Ue+65Z8QmRuemK+53lE2D2MmfqG9vggMvtOxrwULq4zemQyz1KBYAa2r5JThJvZilfRDnOpqXG491/toTseGFTmZcD8TKUhsg9tNmLM7u71SLYNPH48UcB7z4Zukah+gahYQ2E/HpCtXDbGAS6Mfb2px4W2fIRbD9zVjoW+sdB7FpaU0Qs9vw/n0BLBK2xatF88ZgeBchHykjnbuBy/Bqm6euxMYBjmI1NxM0DVvmZNVDbL77HYgd6cuB2I62qRCblIQXH01zqkXnxQm4zwQ0/3ts8GIBu8eBjXp0eTIQxP0GGx/gY7YMJkOszYtrwY+nYHMVxzFcISc6scHTll71NXqhGZu3ZMfj7T79a3VuA/8wMj+siVb+OgYMSf9Mfc3ty/H9O9WkNsFIqcbnZbsR14f2I5kQSz2Ca+Mtd2yF2K8+vlTZnjK+BcZ8diXOo3AcXmj66nGfQKwqSf1cd2iWpD3zfwOxyoPYpOZUFubfJVnYwORUv/r5f0kaXoD94R1fg1gAlw5J+eoZiHXvxTXgD4cuUrafXbQBxrz76SK8L3zIqBjptTechnC6xh4G9rGIqv7rsGlc7X/DJiQ3X7QbYmf82KxmX1+Rsp2qufh0kh2TesDAdbfei8elusYeGU71cyFLs3YGNGt2nQ/vX0fX/OS0X33M7uWYmWm/DuvutYZcoZcsWSIZGRlDDSMyJeYvWRVzl6yM+UtWxdwlM4n4X2lPPfWUzJ49W1avXi3t7eG1IiYyC+YvWRVzl6yM+UtWxdylWIjoRO273/2uHDt2TPbv3y+5ubly9913n3Ps+vXrpaKiQioqKsQnsf0pEZFI+PnL3CWz4dpLVhbR2uvF604SjTauvRQrEZ2oZWdni8PhELvdLrfffrvs3o2/V/1Pa9eulaqqKqmqqpI40fyImWiUhZu/zF0yG669ZGURrb0urKMmGm1ceylWhmwmotPQ0CC5ubkiIvLKK68onXFGSzjFmGYC87XhObI9ARsmBLqwEFIWzIJQ8JE2iPUdz1W2c/Lxq/qc2z/F+zfCa/cR/PJFEOucqhaqp287DmOwNHV0jWb+2rPHa6L4PsRrimKL3NhQISBY5G6LG7qRRyCA+aZ7m22avLRpmiyEI6h5TLHjgzo08/f71GYfRiJmzWkv1hB8czw2sPhZ7TUQS4zD19s+IV/ZDlRj7sZapLnrzU2S2m+rzSbmLjsE42bGY4MOh6jvT5c/AcYkOfG/xo2DKRDTNezIS8DGCv4g5k7tgFrsfdTAfcvtwPfVH8TGMRkuLAjXzS09DseF7qvjXfiY4+LwWyBdA5PqQWysoCuk/1jTgqkv6FK2MzXvXZEbm1vEUkT5axMJxqnrXv37+ThOfTmk91J8D344ZRvE/u4MNt5wDuB78NoZnOulk7AZR6gjRjbEmt7Jg9gbV+P9BzLVhhKBQczln7dNh1jd3lyISQLmUGYcNj3IcKqvm9uGTS0S6vD4q2cKHn99POsViH0nfTHEdrxRrmzfbrsVxmRma7qXYX+0ERPN44ZIj1Wdubhe+CZhfrWVYuOYvhw8dihfdljZ/mb2v8GY5gCu43E2nH+tD5t7XZRYo2z/uXMGjGlxYuMlXdORi5OqIdYRxOeZ51SPr3549HoYk52Ief/sROzi6TPwM+GID0+8O0M+Y/7njLdgzCuiOxYMz5AnajfddJNs375dWlpapKCgQB588EHZvn277N+/X2w2mxQVFckzzzwT8QSIRhLzl6yKuUtWxvwlq2LukpkMeaK2ceNGiK1Zs2ZEJkMUbcxfsirmLlkZ85esirlLZjIyF1AhIiIiIiKiiPFEjYiIiIiIyGQiaiZiBmEXY9qwgFJ/h+E10IhU6Hx1zVB0jUMcJZMhdvQufE72dydAbPw8tZA85ZqhC5/Pi6bHRNChzs3o1DRDuYAEMrEQNy2uHmIOTbOAQhc2E9ncWg4xp0vNLV8AC84dDnyzgkHMI91u4LAHhxxj1/zLx6e5fx3dnueMU5uH+AbwOb16fDbEll+0F2K9fhfE4hzYnCSYMna7y8U3D0rRM2oxdt2HxTCu6kuagv3papOK8vw6GDIxAXN1RiLmeZIdm44MBPExdcXq85PV92yhuxbG+DTNdtw2zLBUO+ZTok2TJzYcF+qUH5t41PqxyF1X+N4bxML0oIE7U7Mf15FUh9ropG4wDca0+zGnC19Xt1tNvkQHXDbpyVPfh7hufJ/9Ser7PNiJr+2/1F4KMVs3fhbH3dgIsfL00xA73KU2d+gcxIZgfzNnO8T+KXAZxHbvK4FYyjH1efvx7uU3xyohZpRjM4asdGyg8K/V2NhjcrramGxZ1sd4X5fivt2yDRuk3NuEjc+mJeJruz0k5Y06bFgkmv3YqgavmQ+xrB+pzavKUzDfZiS8CzHd+unWNCc71I8NeEIbElV7sVlJp2Ytc2gaLzV5PRB77MQVyva2Bb+CMffWXw0xu6bxTWsAm46sStYtXurr8Z0Jb8OIya4miP2xFxvw1PvSIZYdh82viuKale2Vns9gzHCaifAbNSIiIiIiIpPhiRoREREREZHJ8ESNiIiIiIjIZHiiRkREREREZDKWbSYSthFuEqKla2ASMo9wm6Ec/XssoAycweLOuDIsqkz/Kl7JPZpsQXxtBzLV5x4cGBjROZhdIB6bEfT6schd1zgkw4FNCt7egcXZaWXqbQf9+Jh2e3j7gdOJTTYS473K9oBX0/xBc7tBXQMTA/eN+HgsfPb51Odgi8f7HziGDRaK5nshlp2ARfQ9PnwPejxqbOg2EhZjV1/7hA9wfZj4H1goHaozEdefd8uwOL59Oq5d3RPx/R/IxffW0Lzf0CdEl9OaBjbOVsxXZ68mD9sgJPEd+BjuDnVu8W2Yc44ebJpi78YGDzqGG5uahNUUqx4L5I904OdMgrFbnZfRB2PMxBYQcXWp70Mv9kWQwSz1fcnYh3tw/ZkCvOEk/IxqaMTGLP9+ah7E8iaoa2/fIL53T1YthZgjDtfGxGqcrzekl4GrHYbIQBbmqEOzHre0Y7OH6flnIHayQ33QJ1ux8Ul2Cq6pshDXjtdOluG4rRkQ8pWor4ctA/efpHrcB0zeB+dzNmwet/ChD2HY5Z6DynafgZ9RusYhuoYXOqlO3M8Hfeq8mnz4maozNR7zZkXKfoi9/dRCZfuSgb+FMceW/hvEtvXjvqBrqHTjCdy39p4qVLYXFZ2AMbM82BBL1zTF48C1QdfoKrQp1PsD+Nk3HPxGjYiIiIiIyGR4okZERERERGQyPFEjIiIiIiIyGZ6oERERERERmYx1m4mE0bBDRMSRnQWxYCHGeguTlO3EVz6IfG4RNjA5+vgiiNkCWFRbOAMLOeOvrInoMW1xmsJ1DcOHBfOGU9MYYFwMmreYmN2PRePacYLj+oJYTGzHt0FcTrW4ta0jCcbYNI0XDE3jBb8Di3j7+tR5GAFNwwYXFq/rmoTo9LViEa+ETDczHwvVA+/h6/OpD597khP3ocZ+LKz3pqnLYQLOyrIMv18CjWqzCUdaKoxzTi7C29qHbmRhb+qA2LijpyGWmYTvtTGoSWoNmzMkN3XrrCZ/jUQ3jgu9LxEx4rFQP+jCcYFEdZw3BW/nz8Hc9HqwQYWmN4DYNbtNUPNJ7U9U35e4bmzS4PDha5RyIqRAfv8uvHMTsRkitpDlMaD52Lpy7sfK9pHJ2TAmzY7rbFEydpHZ9cZsiCWfxNdy3txaZfuN6hkwJvEQ5l9QM/9FN++DWLdPve3xznEwJj8Bm0SceKsIYrlVmFj9d2EC3jh5j7K94aVKGOP/CNfZCXfh/n7xuOMQe2dFMcRWjT+qbP/x9EwY403D/LZCNxFfVpLU//cFSuyB1H+CcS+2qcd/hW7My4muFojNSTgZ1jw8dmyMMS1FPXb4Yy8229neMR1iuXG43r/TNwViLz3wM2X7m3feDWMWb/lriHUV4XdI/iTNWjYHm7Dde9FryrbLhscmHQH8HMqI74VYmiO8RkuhjV88dmwc5ZiGeS+CjU50+I0aERERERGRyfBEjYiIiIiIyGSGPFGrra2Vyy67TEpLS6WsrEyeeOIJERFpa2uTyspKKSkpkcrKSmlv11zggyjGmL9kVcxdsjLmL1kVc5fMZMgaNafTKY899pjMnTtXuru7Zd68eVJZWSnPP/+8XH755bJu3Tp55JFH5JFHHpFHH310NOb8uTDrwPrmTYRY1wR82vEhF9R0pODF9QJd0ftBtKNkMsTmVeAFaNNd+BvZmgXhXTg1LAb+Zt8IaC42q6Mpv/IVhFdvMlpinb/+JKwB6NUUWOgu5jjOiRe8dgxgvVBinFp7kD8efz/e2IE1WYlJ+F5NTMMPnmNtal1EfirWi/X58Dm19eLvwMen44VSx+Vhjtd3qa/HuET8/XizgfUaSzTlSE8OYj1F9yDWENkS1P9bxbpGbaRzN9Chubi1LhYGuwfzyxavKcTx48VCJQ1vayTgbYOuoUuqDSf+71FXY2cLs3bUcOD92UI+e1wduB8l1mhqGzR11UacplZO9zx18w19rpox9m6cR+BoSF2EEcXPk/8iWvlr9wUlqV6tM20vxb3zrWNTlW1XPOaa7kLN77w1C2ITtmM9T9M8XFw275+jbCecwLwNaBaSQDwev7xXXwSxqeOale0MTT1aigvnOpipueD1LPws6vs0F2LPt6u1q4PZmhqfyZijtadyIOay420LkvDzyWeo+0FnL75ohY1Ya4zPPDqiufbafSKJjeq++ceuchg3OUF9r1t8uC7+Rw/makECfmanOnCfLtZcpHr/gFo3+0YzXqA8LwGPext9WN/cqqkPD62zf+4XP4cxjzVeAbEVGXshNseF9WgdQVyfD3nVPOwO4n47YOC+0KmpW/NoXkefgbnvCDmOTrPjfto1C49XBEs4tYb8Ri03N1fmzp0rIiIej0dKS0ulrq5ONm3aJLfddpuIiNx2223y6quvhveIRKOI+UtWxdwlK2P+klUxd8lMzqtGraamRvbt2ycLFy6UxsZGyc39/L8xubm50tTUNMStiWKL+UtWxdwlK2P+klUxdynWwm7P39PTI6tWrZLHH39cUjQ/CzyX9evXy/r160VExCf41TXRaIgkf5m7ZAZce8nKhrv2en34s2ei0RCNtdc/yPyl4QnrGzWfzyerVq2Sm2++WVauXCkiItnZ2dLQ0CAiIg0NDZKVhdcmExFZu3atVFVVSVVVlcQJ1oUQjbRI85e5S7HGtZesLBprrysOa1+IRlq01l5nPPOXhmfIb9QMw5A1a9ZIaWmp3HXXXWfjy5cvlw0bNsi6detkw4YNct1114X3iKEF1RFeHDrcC17Hb/kQYuPDuPsw22lEbj2Wwd6S/R7EnvrmDRCzyf6oTcPQFffrXlsNWxBf77lT1IsvYun26Ip6/p6nQDz+L2Smpx5i0+Mxpit49XvwNQ8a6vuV7MJvT+oDWPzr9WMjg0QnNkaYlKFeePO2XLxA7kNHroZYbzMW5/rS8DEdNnxO45PU/0IGDHwdk87gXrq9H8ftPYYNhWZOqoPYGVc4K8PoiXXuno9gt2ZPD3fnxxr3qApvNQv/tuHc34h/foQplvOIVv76E+zSNkNtCLDs2vdh3Ict6n6ua2Z0uhUvOr7ma3+C2HNFF0PMeQjnNnGCegHigTw8pOp9Cw/mHbOxQcOENGyy0dSHDSVCFXuaIZY+CRtM9LVlQmzS9AaIwevWhmt21yz8nFg67TOIne7F19uZgFk5EHLl9yUTj8KYXZdcBLGEbRCKimiuvQ5vUDy16mdy6Ge2iMifW9QLS2e7cQEt99RC7EgfNnH5uD8PYnudEyCW4FAbkaVqGtMkOfF4IjMO5zYpHn8GGnqx6Q8HcA7fHb8dYqf86RDb3DsVYof68HmmO9VGHh934Zg+Pzb9GQzgvjvgx+YtqfH4Gs3PUI97jwg26Wmeg8cmqWE2ExnyRG3nzp3ywgsvyKxZs6S8/PNONQ899JCsW7dObrjhBnnuuedkwoQJ8vLLL4f3iESjiPlLVsXcJStj/pJVMXfJTIY8UbvkkkvEOMe3Xtu2jdC/M4iihPlLVsXcJStj/pJVMXfJTM6r6yMRERERERGNPJ6oERERERERmUzY7fmjJtLmIZHej6YxRvz2bIhdOq5a2X7xn6+CMVm/xCYK4Tr22CJl+/CflT4RAAAOT0lEQVTUX8KYqa9/B2M7qyJ+zJFmOPG1nZqsFpTuucD/F+D1YCH2BFeLZiTy2LFoNW8uFn+HFsiX5eKYoBfn4UzEImFvEMe57GrDmT29RTCmu9cNMUcyNqpxOrGQvKkjGWJXFx9Wto/3YCH8scsx/zIcfRDzpGGs24tdEPuz1fvDcmYiGm22gIirW/28f+XdBTDOiA8q22XTsfFCj2a/f+4TbBzi16yXkojHHDlJalOQAT82gPqkHBuCBDpxvWxPTMDHDNHRi2P+eGQuxAyn5vgoR9M4TGNapvoZ/sEEXJ9tjiDEPjxTCLGC1E6IdfrwObxXX6Rs95zCVviFn+L8+yFiQj39Yt+xTwm9/OaXYNiPr1Pr3XZ0TIcxfzyDzS26NDk9PhEvCZCiaQCSEaeOS3XiZ6Xbhq97ux87WQ7aMfcDIa2XzgxiU7OdwRKI+TTHIYOaWGgzFBGRNq96rJCXgDnY7cf9r6Y7A2ItnZj7A4l42vRuYIqyfXXOQZxrU+RtrS7so2giIiIiIiIT4okaERERERGRyfBEjYiIiIiIyGR4okZERERERGQyo9pMJJiWJH1LFyoxxyAWpbo61QJBZ1MXjJGuHggZfVhaGuzBcV2DWEh4S8oBZbvz9kQYs++PRRDzn8SC5e6/WgSx3698Qtn+1klsVjL9jk8ghq/OKAizUYthx+LIDn/o64YNMS4k/ePxfyG/b6yAWFFSK8QmJzRD7HQztrhwxav7S7cP89vpxqJbnx+Lc+02fO/TXWqB8emBNBgTDOLzdGgah/g1j+nrwmLoQnebst2hKUA3XDjXWj/O7asTsbC3L+iC2DYjH2JEFFuGQ2QwRf2scbfgZ08wTo3NW3wKxrz06TyIxe/FxgipLbi2tCzGpgr1PWpzhAw3NmNIT8XGDoE/jsP7KseGSZkFHcq2bp1NaNA0gMK+EdJTgM+p14vrYIJTXY/tnXiYGEzCtb2vGtfemi78vCpaWgMx2w51XCJOSzonYcxVhzErmPzD9yD29EfXq2P+xxEYc00OHiPu7ZoAsVOaxhgH+vMgFmdXjzAT47wwxq1p2OFy4PtvF8yvYEgzkSQH3n+SE5uaZcTjPuNx4LGk3Tb0EbJDM6/dnUUQy07EnaY4BRu/+Q3cBxenHlO2//UENijK/idsRtiOfYC0+I0aERERERGRyfBEjYiIiIiIyGR4okZERERERGQyPFEjIiIiIiIymVFtJhKIF+kqUgtfeyZortadqRbtJnmw2YDPhwXAA+3YREGCeP+2eiyE/HLr3yjbzoN4//Ffw7vvXDgeYpdNxYLPu499Xdl23YNXPA8OHIKYPRGbmgT7sGA5Fhy9WGT65o5yZXuKvD9a0zGlAKauJGuKZ7v9mLsZDk3DHE2fl8H+OGW71YU54x/EXd2Pdb1a0xIble3XG8vCup1N05jEOxCHAx04bk/nRGU7aOB+7OjB/zMdH8yG2GAQn3unpjmJHXsFEFGMOfuDkvmx2ijszCJc42x+dY148fUlMMbAvhvSMw0XQm8arlOuJs06cjBXvd1VTTCmtRU/6+OzNOtZN06u45DadMTVrmuiAiHx4/ImiQ142/7GLIh9lqWux5qeUGLvxAcdyMPjAXsLjjtcjU2bnLnqY9onYjOJlH/XfK7h1MzJHvLeBvFFTf2teqzU+lu8m9+vwiZ0C//3hxD7WtEBiE13NUIsLqRdnVvTnCNJ0zRuQHMgovvW593+QmU7oBn15/ZSiOmahzX2pUAsTtPUJJTu2KHfj3nZ2Y/HYA47Ps+B7dj058Sh6cp26hZ8T4aD36gRERERERGZDE/UiIiIiIiITGbIE7Xa2lq57LLLpLS0VMrKyuSJJz6/HtgDDzwg+fn5Ul5eLuXl5bJly5YRnyzR+WDukpUxf8mqmLtkZcxfMpMha9ScTqc89thjMnfuXOnu7pZ58+ZJZWWliIjceeedcs8994z4JIkiwdwlK2P+klUxd8nKmL9kJkOeqOXm5kpu7ucFsx6PR0pLS6WuLrLLwcc19krOL/Dq3JFw5uNV1r2TsZHAwHi8xH13AXZ4MGxqrLcQiyrdC9ohNjUZGz6889YsiBU/36xsB45g4xAdszQO0XH0YhH2puvXK9t33bN4tKYDopm7kXL2YjFqUWIrxN46UwKxKYnNEMsa1wWx8Ylq4XVrPxZdO8ZhnvoD+IV6cz8Wvp9KyFC2PXEDMMbtxkJyHWcyNlJJdmMstABYVxBsL8B9oy+I+3uPpqPLia5xEEs9Ya7SdDPkL1Ekopq7Pf1i27lfvf+dw53hCHkCQ6mjP4sLRvvckbnfqK+9muYhkUj6wwcQ++QPOO4TmQQx2/zlEOvPUZt2xLdqGp1NxMYeKcew2Yt9ED8/gwcO4+QAHpvo4bFPeEcdCI8SRLAt4Ll8FuGjRu68atRqampk3759snDhQhEReeqpp2T27NmyevVqaW/Hkxgis2DukpUxf8mqmLtkZcxfirWwT9R6enpk1apV8vjjj0tKSop897vflWPHjsn+/fslNzdX7r77bu3t1q9fLxUVFVJRUSE+wbN1opHG3CUrY/6SVTF3ycqYv2QGYZ2o+Xw+WbVqldx8882ycuVKERHJzs4Wh8Mhdrtdbr/9dtm9e7f2tmvXrpWqqiqpqqqSONFcVIpoBDF3ycqYv2RVzF2yMuYvmcWQNWqGYciaNWuktLRU7rrrrrPxhoaGs7/hfeWVV2TmzJkjN0sNf109xOyaGFbr6GOR0lx/WCYJ/pY5Or9QNpfAwSMQu/b/fU/ZLhH8TfVoMUPuZn6EdVSNg3jhxm8XYdHFP/98BcRsmjKqE+PU+q2EFszKgOYCqN1TcNw1l2PtZGj9XCCI/9+5YiLmwmddeDHVRCfWNX68A+vz2uzqL8b9KVgz6mrDebySMgdi35uyDWI13VijZntNrYPR7dujyQz5SxQJ5i5Z2VjMX+PDjyGGl3hGKWG2lcBPaIqWIU/Udu7cKS+88ILMmjVLysvLRUTkoYceko0bN8r+/fvFZrNJUVGRPPPMMyM+WaLzwdwlK2P+klUxd8nKmL9kJkOeqF1yySViGPi/5WXLlo3IhIiihblLVsb8Jati7pKVMX/JTM6r6yMRERERERGNPJ6oERERERERmcyQP30kOh8l/zN2zUPMyLbrAMQO/tMiiL21uAxi017YB7HgAF5sOlK6Czzu0fzvJkWODXlf+staYnOfbs2oImkZ8v7D5RiPz+rvf4U/V7G/j5ehzfOdjto8iIiIiIaL36gRERERERGZDE/UiIiIiIiITIYnakRERERERCbDEzUiIiIiIiKTGdVmIq5xdmkvOiHNzc0yXlP0byVWfw5mm39NTU2sp/CF/jN3RaLw2h0+AaFMTTeO1hmRP8QXMdt7f76+eP742ib9Q3j32z43svmYPXdFuPaaidnm76ox9/9ro7r2xhjnH11ce0eX1Z+D2eYfbv7aDN1V/UZYRUWFVFVVjfbDRpXVn4PV5x9LVn/tOP8L11h47az+HKw+/1iy+mvH+V+4xsJrZ/XnYNX5m/tfaURERERERBcgnqgRERERERGZjOOBBx54IBYPPG/evFg8bFRZ/TlYff6xZPXXjvO/cI2F187qz8Hq848lq792nP+Fayy8dlZ/Dlacf0xq1IiIiIiIiOjc+NNHIiIiIiIik+GJGhERERERkcmM+onaG2+8IdOmTZPi4mJ55JFHRvvhz9vq1aslKytLZs6ceTbW1tYmlZWVUlJSIpWVldLe3h7DGX6x2tpaueyyy6S0tFTKysrkiSeeEBFrPQezsFruijB/6S+slr/MXfpPVstdEeYv/YXV8pe5azLGKPL7/cbkyZONY8eOGYODg8bs2bONgwcPjuYUztuOHTuMPXv2GGVlZWdj3//+942HH37YMAzDePjhh40f/OAHsZrekOrr6409e/YYhmEYXV1dRklJiXHw4EFLPQczsGLuGgbzlz5nxfxl7pJhWDN3DYP5S5+zYv4yd81lVE/Udu3aZVx55ZVntx966CHjoYceGs0pROTEiRNKwk6dOtWor683DOPzhJg6dWqspnbeli9fbrz55puWfg6xYNXcNQzmL1k3f5m7ZNXcNQzmL1k3f5m75jGqP32sq6uTwsLCs9sFBQVSV1c3mlOIisbGRsnNzRURkdzcXGlqaorxjMJTU1Mj+/btk4ULF1r2OcTKWMldEebvhWis5K9V33fmbuTGSu6KMH8vRGMlf636vo+F3B3VEzVDcyUAm802mlO4YPX09MiqVavk8ccfl5SUlFhPx3KYu7HF/B0e5m/sMHeHh7kbW8zf4WH+xs5Yyd1RPVErKCiQ2tras9unT5+WvLy80ZxCVGRnZ0tDQ4OIiDQ0NEhWVlaMZ/TFfD6frFq1Sm6++WZZuXKliFjvOcTaWMldEeu998zf4Rsr+Wu19525O3xjJXdFrPfeM3+Hb6zkr9Xe97GUu6N6ojZ//nyprq6WEydOiNfrlZdeekmWL18+mlOIiuXLl8uGDRtERGTDhg1y3XXXxXhG52YYhqxZs0ZKS0vlrrvuOhu30nMwg7GSuyLWeu+Zv9ExVvLXSu87czc6xkruiljrvWf+RsdYyV8rve9jLndHuyjutddeM0pKSozJkycbP/3pT0f74c/bjTfeaOTk5BhOp9PIz883nn32WaOlpcVYunSpUVxcbCxdutRobW2N9TTP6Z133jFExJg1a5YxZ84cY86cOcZrr71mqedgFlbLXcNg/tJfWC1/mbv0n6yWu4bB/KW/sFr+MnfNxWYYmh/QEhERERERUcyM+gWviYiIiIiI6IvxRI2IiIiIiMhkeKJGRERERERkMjxRIyIiIiIiMhmeqBEREREREZkMT9SIiIiIiIhMhidqREREREREJvP/AQb5IOHGDBORAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utility functions\n",
    "\n",
    "def flatten(arr):\n",
    "    arr = arr.reshape(arr.shape[0], -1)\n",
    "    return arr\n",
    "\n",
    "def plot_labels(data, labels, flatten=False):\n",
    "\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    uniq_labels = np.unique(labels)\n",
    "\n",
    "    fig, ax = plt.subplots(2,5, figsize=(15, 6))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    ax = ax.reshape(-1)\n",
    "\n",
    "    for i, label in enumerate(uniq_labels):\n",
    "\n",
    "        img = data[np.where(labels == label)[0][0]]\n",
    "\n",
    "        ax[i].set_title(class_names[label])\n",
    "        \n",
    "        if flatten:\n",
    "            img = img.reshape(28, 28)\n",
    "\n",
    "        ax[i].imshow(img)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_labels(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000,), (6000,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = flatten(train_images)\n",
    "test_images = flatten(test_images)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, shuffle=True)\n",
    "train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gi2ksmfk\n",
      "Sweep URL: https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"Sweep Test Master\",\n",
    "  \"method\": \"grid\",\n",
    "  \"parameters\": {\n",
    "        \"epochs\": {\n",
    "            \"values\": [5, 10]\n",
    "        },\n",
    "        \"n_layers\": {\n",
    "            \"values\": [3, 4, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: kv1shhj5 with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 3\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">generous-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/kv1shhj5\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/kv1shhj5</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010250-kv1shhj5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.707586 Train Accuracy: 0.744576 Val Loss: 0.479191 Val Accuracy: 0.829953\n",
      "Epoch: 2 Train Loss: 0.463202 Train Accuracy: 0.832161 Val Loss: 0.423518 Val Accuracy: 0.848238\n",
      "Epoch: 3 Train Loss: 0.413866 Train Accuracy: 0.850007 Val Loss: 0.402035 Val Accuracy: 0.853890\n",
      "Epoch: 4 Train Loss: 0.384985 Train Accuracy: 0.860264 Val Loss: 0.384555 Val Accuracy: 0.860539\n",
      "Epoch: 5 Train Loss: 0.365588 Train Accuracy: 0.866465 Val Loss: 0.371196 Val Accuracy: 0.865525\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14596<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010250-kv1shhj5\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010250-kv1shhj5\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.36559</td></tr><tr><td>train_acc</td><td>0.86647</td></tr><tr><td>val_loss</td><td>0.3712</td></tr><tr><td>val_acc</td><td>0.86553</td></tr><tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1615404781</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁▅▆▇█</td></tr><tr><td>_runtime</td><td>▁▃▅▆█</td></tr><tr><td>_timestamp</td><td>▁▃▅▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">generous-sweep-1</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/kv1shhj5\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/kv1shhj5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: g4dlo03v with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 4\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">toasty-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/g4dlo03v\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/g4dlo03v</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010306-g4dlo03v</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.723787 Train Accuracy: 0.735560 Val Loss: 0.477161 Val Accuracy: 0.827959\n",
      "Epoch: 2 Train Loss: 0.465409 Train Accuracy: 0.832439 Val Loss: 0.419655 Val Accuracy: 0.846576\n",
      "Epoch: 3 Train Loss: 0.416455 Train Accuracy: 0.849211 Val Loss: 0.388514 Val Accuracy: 0.861536\n",
      "Epoch: 4 Train Loss: 0.386872 Train Accuracy: 0.859282 Val Loss: 0.371048 Val Accuracy: 0.869681\n",
      "Epoch: 5 Train Loss: 0.366316 Train Accuracy: 0.866669 Val Loss: 0.362729 Val Accuracy: 0.872673\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1296<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010306-g4dlo03v\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010306-g4dlo03v\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.36632</td></tr><tr><td>train_acc</td><td>0.86667</td></tr><tr><td>val_loss</td><td>0.36273</td></tr><tr><td>val_acc</td><td>0.87267</td></tr><tr><td>_runtime</td><td>14</td></tr><tr><td>_timestamp</td><td>1615404800</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁▄▆██</td></tr><tr><td>_runtime</td><td>▁▃▅▇█</td></tr><tr><td>_timestamp</td><td>▁▃▅▇█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">toasty-sweep-2</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/g4dlo03v\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/g4dlo03v</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: d6gj8f92 with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 5\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">amber-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/d6gj8f92\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/d6gj8f92</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010325-d6gj8f92</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.823852 Train Accuracy: 0.693091 Val Loss: 0.560746 Val Accuracy: 0.776928\n",
      "Epoch: 2 Train Loss: 0.499495 Train Accuracy: 0.820683 Val Loss: 0.465609 Val Accuracy: 0.826130\n",
      "Epoch: 3 Train Loss: 0.438374 Train Accuracy: 0.841010 Val Loss: 0.430273 Val Accuracy: 0.842254\n",
      "Epoch: 4 Train Loss: 0.403838 Train Accuracy: 0.853784 Val Loss: 0.411828 Val Accuracy: 0.842919\n",
      "Epoch: 5 Train Loss: 0.381374 Train Accuracy: 0.860375 Val Loss: 0.378228 Val Accuracy: 0.858211\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12372<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010325-d6gj8f92\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010325-d6gj8f92\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.38137</td></tr><tr><td>train_acc</td><td>0.86037</td></tr><tr><td>val_loss</td><td>0.37823</td></tr><tr><td>val_acc</td><td>0.85821</td></tr><tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1615404816</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇█</td></tr><tr><td>_runtime</td><td>▁▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▄▅▇█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">amber-sweep-3</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/d6gj8f92\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/d6gj8f92</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: s3cec4oi with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 3\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">peach-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/s3cec4oi\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/s3cec4oi</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010341-s3cec4oi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.724059 Train Accuracy: 0.734764 Val Loss: 0.531889 Val Accuracy: 0.808344\n",
      "Epoch: 2 Train Loss: 0.464440 Train Accuracy: 0.829736 Val Loss: 0.465766 Val Accuracy: 0.828624\n",
      "Epoch: 3 Train Loss: 0.411830 Train Accuracy: 0.847823 Val Loss: 0.451901 Val Accuracy: 0.833777\n",
      "Epoch: 4 Train Loss: 0.381701 Train Accuracy: 0.859338 Val Loss: 0.442429 Val Accuracy: 0.840592\n",
      "Epoch: 5 Train Loss: 0.362238 Train Accuracy: 0.866614 Val Loss: 0.426902 Val Accuracy: 0.848238\n",
      "Epoch: 6 Train Loss: 0.346477 Train Accuracy: 0.870723 Val Loss: 0.417017 Val Accuracy: 0.852560\n",
      "Epoch: 7 Train Loss: 0.334334 Train Accuracy: 0.876574 Val Loss: 0.421026 Val Accuracy: 0.851895\n",
      "Epoch: 8 Train Loss: 0.324204 Train Accuracy: 0.879961 Val Loss: 0.400390 Val Accuracy: 0.858211\n",
      "Epoch: 9 Train Loss: 0.315980 Train Accuracy: 0.883368 Val Loss: 0.406612 Val Accuracy: 0.859043\n",
      "Epoch: 10 Train Loss: 0.308049 Train Accuracy: 0.884849 Val Loss: 0.396572 Val Accuracy: 0.863531\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8072<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010341-s3cec4oi\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010341-s3cec4oi\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.30805</td></tr><tr><td>train_acc</td><td>0.88485</td></tr><tr><td>val_loss</td><td>0.39657</td></tr><tr><td>val_acc</td><td>0.86353</td></tr><tr><td>_runtime</td><td>16</td></tr><tr><td>_timestamp</td><td>1615404837</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▁▂▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▇▇▇▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">peach-sweep-4</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/s3cec4oi\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/s3cec4oi</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 7ndumqk6 with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 4\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bumbling-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/7ndumqk6\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/7ndumqk6</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010401-7ndumqk6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.806429 Train Accuracy: 0.692776 Val Loss: 0.499202 Val Accuracy: 0.824634\n",
      "Epoch: 2 Train Loss: 0.472711 Train Accuracy: 0.826144 Val Loss: 0.455530 Val Accuracy: 0.837766\n",
      "Epoch: 3 Train Loss: 0.420084 Train Accuracy: 0.844657 Val Loss: 0.428688 Val Accuracy: 0.848404\n",
      "Epoch: 4 Train Loss: 0.392173 Train Accuracy: 0.855580 Val Loss: 0.401063 Val Accuracy: 0.858710\n",
      "Epoch: 5 Train Loss: 0.371741 Train Accuracy: 0.863485 Val Loss: 0.390061 Val Accuracy: 0.860705\n",
      "Epoch: 6 Train Loss: 0.355661 Train Accuracy: 0.869002 Val Loss: 0.375442 Val Accuracy: 0.866523\n",
      "Epoch: 7 Train Loss: 0.343848 Train Accuracy: 0.873871 Val Loss: 0.369286 Val Accuracy: 0.867520\n",
      "Epoch: 8 Train Loss: 0.332831 Train Accuracy: 0.878666 Val Loss: 0.364717 Val Accuracy: 0.871177\n",
      "Epoch: 9 Train Loss: 0.323380 Train Accuracy: 0.882331 Val Loss: 0.362498 Val Accuracy: 0.869681\n",
      "Epoch: 10 Train Loss: 0.314731 Train Accuracy: 0.884886 Val Loss: 0.367900 Val Accuracy: 0.870512\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7808<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010401-7ndumqk6\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010401-7ndumqk6\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.31473</td></tr><tr><td>train_acc</td><td>0.88489</td></tr><tr><td>val_loss</td><td>0.3679</td></tr><tr><td>val_acc</td><td>0.87051</td></tr><tr><td>_runtime</td><td>16</td></tr><tr><td>_timestamp</td><td>1615404857</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">bumbling-sweep-5</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/7ndumqk6\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/7ndumqk6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 874lshk1 with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 5\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sleek-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/gi2ksmfk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/874lshk1\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/874lshk1</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010421-874lshk1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.890992 Train Accuracy: 0.659730 Val Loss: 0.547724 Val Accuracy: 0.806682\n",
      "Epoch: 2 Train Loss: 0.522716 Train Accuracy: 0.810704 Val Loss: 0.465211 Val Accuracy: 0.829289\n",
      "Epoch: 3 Train Loss: 0.449406 Train Accuracy: 0.836326 Val Loss: 0.422801 Val Accuracy: 0.844415\n",
      "Epoch: 4 Train Loss: 0.410553 Train Accuracy: 0.850211 Val Loss: 0.401962 Val Accuracy: 0.850565\n",
      "Epoch: 5 Train Loss: 0.385624 Train Accuracy: 0.858949 Val Loss: 0.398798 Val Accuracy: 0.853557\n",
      "Epoch: 6 Train Loss: 0.368754 Train Accuracy: 0.864207 Val Loss: 0.396831 Val Accuracy: 0.856383\n",
      "Epoch: 7 Train Loss: 0.353456 Train Accuracy: 0.869354 Val Loss: 0.388774 Val Accuracy: 0.857713\n",
      "Epoch: 8 Train Loss: 0.342268 Train Accuracy: 0.873889 Val Loss: 0.384002 Val Accuracy: 0.862699\n",
      "Epoch: 9 Train Loss: 0.333036 Train Accuracy: 0.876203 Val Loss: 0.378483 Val Accuracy: 0.863531\n",
      "Epoch: 10 Train Loss: 0.324798 Train Accuracy: 0.879499 Val Loss: 0.381444 Val Accuracy: 0.862866\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15928<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010421-874lshk1\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\wandb\\run-20210311_010421-874lshk1\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.3248</td></tr><tr><td>train_acc</td><td>0.8795</td></tr><tr><td>val_loss</td><td>0.38144</td></tr><tr><td>val_acc</td><td>0.86287</td></tr><tr><td>_runtime</td><td>15</td></tr><tr><td>_timestamp</td><td>1615404876</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sleek-sweep-6</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/874lshk1\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/874lshk1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
