{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "import wandb\n",
    "from sklearn.datasets import make_classification\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl \n",
    "mpl.rcParams['figure.facecolor'] = \"white\"\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used for WandB sweep\n",
    "def train():\n",
    "\n",
    "    config_defaults = {\n",
    "        'n_layers': 3,\n",
    "        'layer_size': 32,\n",
    "        'weight_decay': 0,\n",
    "        'lr': 1e-3,\n",
    "        'optimizer': 'sgd',\n",
    "        'batch_size': 32,\n",
    "        'init_method': 'random',\n",
    "        'activation': 'relu',\n",
    "        'epochs': 5\n",
    "    }\n",
    "\n",
    "    wandb.init(config=config_defaults, magic=True)\n",
    "\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "    train_images = flatten(train_images / 255.0)\n",
    "    test_images = flatten(test_images / 255.0)   \n",
    "\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, shuffle=True)\n",
    "\n",
    "    model = NeuralNet(create_layers(wandb.config.n_layers, \n",
    "                                    wandb.config.layer_size, \n",
    "                                    wandb.config.activation, \n",
    "                                    wandb.config.weight_decay,\n",
    "                                    wandb.config.init_method))\n",
    "\n",
    "    \n",
    "    model.compile(loss=CrossEntropyLossFromLogits(), optimizer=get_optimizer(wandb.config.optimizer, wandb.config.lr))\n",
    "    \n",
    "    model.fit(train_images, train_labels, val_images, val_labels, batch_size=wandb.config.batch_size, epochs=wandb.config.epochs)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module to create template classes for Autodifferentiable losses/activations/layers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AutoDiffFunction():\n",
    "    \"\"\"Format for any function in general which has to be auto-differentiable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwds) -> None:\n",
    "        self.saved_for_backward = {}\n",
    "        self.grad = {}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "\n",
    "        output = self.forward(*args, **kwds)\n",
    "        self.grad = self.compute_grad(*args, **kwds)\n",
    "        return output\n",
    "\n",
    "    def forward(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def compute_grad(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def backward(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Layer(AutoDiffFunction):\n",
    "    \"\"\"Format to create your own custom layer for the model\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwds) -> None:\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.weights = {}\n",
    "        self.optimizer = None\n",
    "\n",
    "    def initialize_weights(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        self.optimizer.step(self)\n",
    "\n",
    "\n",
    "class Loss(AutoDiffFunction):\n",
    "    \"\"\"Format to create a custom loss function\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        pass \n",
    "\n",
    "    def backward(self):\n",
    "        return self.grad[\"x\"]\n",
    "\n",
    "    def compute_grad(self, y_true, y_pred):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Optimizer():\n",
    "    \"\"\"Format to create a custom optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwds):\n",
    "        self.remember = {}\n",
    "        pass\n",
    "\n",
    "    def add_params(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def step(self, layer):\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(AutoDiffFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = 1/(1 + np.exp(-x))\n",
    "        return self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        y = self.saved_for_backward\n",
    "\n",
    "        return {\"x\": y*(1-y)}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]      \n",
    "\n",
    "\n",
    "class RelU(AutoDiffFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = np.where(x>0.0, 1.0, 0.0)\n",
    "\n",
    "        return x * self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        return {\"x\": self.saved_for_backward}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]\n",
    "    \n",
    "class Tanh(AutoDiffFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.saved_for_backward = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "        return self.saved_for_backward\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        y = self.saved_for_backward\n",
    "\n",
    "        return {\"x\": 1 - y**2}\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]\n",
    "    \n",
    "class Softmax(AutoDiffFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        v = np.exp(x)\n",
    "        self.saved_for_backward = v\n",
    "\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return dy * self.grad[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(Layer):\n",
    "    def __init__(self, in_dim, out_dim, weight_decay=None, init_method=\"random\") -> None:\n",
    "        super().__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.init_method = init_method\n",
    "        self.initialize_weights(in_dim, out_dim)\n",
    "\n",
    "    def initialize_weights(self, in_dim, out_dim):\n",
    "        \n",
    "        if self.init_method == \"random\":\n",
    "            scaling_factor = 1/np.sqrt(in_dim)\n",
    "            self.weights[\"w\"] = np.random.randn(in_dim, out_dim) * scaling_factor\n",
    "            self.weights[\"b\"] = np.random.randn(1, out_dim) * scaling_factor\n",
    "        elif self.init_method == \"xavier\":\n",
    "            lim = np.sqrt(6 / (in_dim + out_dim))\n",
    "            self.weights[\"w\"] = np.random.uniform(low=-lim, high=lim, size=(in_dim, out_dim))\n",
    "            self.weights[\"b\"] = np.random.uniform(low=-lim, high=lim, size=(1, out_dim))\n",
    "\n",
    "    def compute_grad(self, x):\n",
    "        \n",
    "        gradients = {}\n",
    "\n",
    "        # y = x * w + b        \n",
    "        # we compute gradients wrt w and x \n",
    "        # gradient wrt b is not required explicitly since we know that it's value is 1\n",
    "        gradients[\"w\"] = self.saved_for_backward[\"x\"].T\n",
    "        gradients[\"x\"] = self.weights[\"w\"].T\n",
    "\n",
    "        return gradients\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x @ self.weights[\"w\"] + self.weights[\"b\"]\n",
    "        self.saved_for_backward[\"x\"] = x\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, dy):\n",
    "        \n",
    "        # calculating gradients wrt input to pass on to previous layer for backprop\n",
    "        dx = dy @ self.grad[\"x\"]\n",
    "        \n",
    "        # calculating gradients wrt weights\n",
    "        dw = self.grad[\"w\"] @ dy\n",
    "        db = np.sum(dy, axis=0, keepdims=True)\n",
    "\n",
    "        # accomodating for weight_decay / regularization\n",
    "        if self.weight_decay:\n",
    "            dw = dw + 2 * self.weight_decay * self.weights[\"w\"]\n",
    "            db = db + 2 * self.weight_decay * self.weights[\"b\"]\n",
    "\n",
    "        self.absolute_gradients = {\"w\": dw, \"b\": db}\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def update_weights(self):\n",
    "        self.optimizer.step(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossFromLogits(Loss):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        v = np.exp(x)\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def encode(self, y): \n",
    "        encoded_y = np.zeros(shape=(len(y), self.n_classes))\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "\n",
    "        return encoded_y\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "         \n",
    "        probabilities = self.softmax(y_pred)\n",
    "        y_true_encoded = self.encode(y_true)\n",
    "\n",
    "        loss_value = np.mean(np.sum(- y_true_encoded * np.log(probabilities), axis=1))\n",
    "\n",
    "        self.saved_for_backward[\"probabilities\"] = probabilities\n",
    "        self.saved_for_backward[\"y_true\"] = y_true_encoded\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def compute_grad(self, y_pred, y_true):\n",
    "\n",
    "        return {\"x\": self.saved_for_backward[\"probabilities\"] - self.saved_for_backward[\"y_true\"]}\n",
    "    \n",
    "class MSELossFromLogits(Loss):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        maxes_vec = np.expand_dims(np.amax(x,axis=1), axis=1)\n",
    "        maxes_arr = np.tile(maxes_vec, (1,x.shape[1]))\n",
    "        v = np.exp(x - maxes_arr)\n",
    "\n",
    "        return v / np.sum(v, axis=1, keepdims=True)\n",
    "\n",
    "    def encode(self, y): \n",
    "        encoded_y = np.zeros(shape=(len(y), self.n_classes))\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "\n",
    "        return encoded_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def indicator(i, j):\n",
    "        ind = {True: 1, False: 0}\n",
    "        return ind[i==j]\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "         \n",
    "        probabilities = self.softmax(y_pred)\n",
    "        y_true_encoded = self.encode(y_true)\n",
    "\n",
    "        loss_value = np.mean(np.sum((probabilities - y_true_encoded)**2, axis=1))\n",
    "\n",
    "        self.saved_for_backward[\"probabilities\"] = probabilities\n",
    "        self.saved_for_backward[\"y_true\"] = y_true_encoded\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def compute_grad(self, y_pred, y_true):\n",
    "\n",
    "        probs = self.saved_for_backward[\"probabilities\"]\n",
    "        labels = self.saved_for_backward[\"y_true\"]\n",
    "        grad = np.zeros(shape=(len(y_true), self.n_classes))\n",
    "        \n",
    "        for point_counter in range(len(y_true)):\n",
    "            res = 0\n",
    "            for i in range(self.n_classes):\n",
    "                for j in range(self.n_classes):\n",
    "                    \n",
    "                    res = probs[point_counter, j] * (probs[point_counter, j] - labels[point_counter, j]) * (self.indicator(i,j) - probs[point_counter, i])\n",
    "                \n",
    "                grad[point_counter, i] = res\n",
    "        \n",
    "        return {\"x\": grad}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, lr=1e-2):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, layer):\n",
    "\n",
    "        for weight_name, _ in layer.weights.items():\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - self.lr * layer.absolute_gradients[weight_name]\n",
    "            \n",
    "class Momentum(Optimizer):\n",
    "    def __init__(self, lr=1e-3, gamma=0.9):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #Momentum update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            self.remember[weight_name][\"v\"] = self.gamma * self.remember[weight_name][\"v\"] + \\\n",
    "                                                self.lr * layer.absolute_gradients[weight_name]\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - self.remember[weight_name][\"v\"]\n",
    "\n",
    "class NAG(Optimizer):\n",
    "    def __init__(self, lr=1e-3, gamma=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma \n",
    "\n",
    "    def step(self, layer):\n",
    "\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] + (self.gamma**2) * self.remember[weight_name][\"v\"] - \\\n",
    "                                            (1 + self.gamma) * self.lr * layer.absolute_gradients[weight_name]\n",
    "\n",
    "            self.remember[weight_name][\"v\"] = self.remember[weight_name][\"v\"] * self.gamma - \\\n",
    "                                                self.lr * layer.absolute_gradients[weight_name]\n",
    "\n",
    "class RMSprop(Optimizer):\n",
    "    def __init__(self, lr=1e-3, beta=0.9, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #RMSprop update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            self.remember[weight_name][\"v\"] = self.beta * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta) * (layer.absolute_gradients[weight_name] ** 2)\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - (self.lr / (np.sqrt(self.remember[weight_name][\"v\"] + \\\n",
    "                                                self.epsilon))) * layer.weights[weight_name]\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1\n",
    "        \n",
    "    def step(self, layer):\n",
    "        \n",
    "        #Initialise update history\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "                self.remember[weight_name][\"m\"] = np.zeros_like(weight)\n",
    "        \n",
    "        #Adam update rule\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            \n",
    "            #Update m_t and v_t\n",
    "            self.remember[weight_name][\"m\"] = self.beta_1 * self.remember[weight_name][\"m\"] + \\\n",
    "                                                (1 -self.beta_1) * layer.absolute_gradients[weight_name]\n",
    "            \n",
    "            self.remember[weight_name][\"v\"] = self.beta_2 * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta_2) * (layer.absolute_gradients[weight_name]**2)\n",
    "            \n",
    "            #Bias correction\n",
    "            m_hat = self.remember[weight_name][\"m\"]/(1 - self.beta_1 ** self.t)\n",
    "            v_hat = self.remember[weight_name][\"v\"]/(1 - self.beta_2 ** self.t)\n",
    "            \n",
    "            #Update parameters\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - (self.lr / (np.sqrt(v_hat + self.epsilon))) * m_hat\n",
    "            \n",
    "        self.t += 1\n",
    "            \n",
    "class Nadam(Optimizer):\n",
    "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1\n",
    "\n",
    "    def step(self, layer):\n",
    "        \n",
    "        # we have 2 parameters to remember m(t) and v(t) for all weights in the layer\n",
    "        if self.remember == {}:\n",
    "            for weight_name, weight in layer.weights.items():\n",
    "                self.remember[weight_name] = {}\n",
    "                self.remember[weight_name][\"v\"] = np.zeros_like(weight)\n",
    "                self.remember[weight_name][\"m\"] = np.zeros_like(weight)\n",
    "\n",
    "        for weight_name, weight in layer.weights.items():\n",
    "            \n",
    "            self.remember[weight_name][\"m\"] = self.beta_1 * self.remember[weight_name][\"m\"] + \\\n",
    "                                                (1 -self.beta_1) * layer.absolute_gradients[weight_name]\n",
    "\n",
    "            self.remember[weight_name][\"v\"] = self.beta_2 * self.remember[weight_name][\"v\"] + \\\n",
    "                                                (1 - self.beta_2) * layer.absolute_gradients[weight_name]**2\n",
    "\n",
    "            # bias correction step \n",
    "            m_hat = self.remember[weight_name][\"m\"]/(1 - self.beta_1 ** self.t)\n",
    "            v_hat = self.remember[weight_name][\"v\"]/(1 - self.beta_2 ** self.t)\n",
    "\n",
    "            d = self.lr / (np.sqrt(v_hat) + self.epsilon) * (self.beta_1*m_hat + (1-self.beta_1)/\n",
    "                                                (1-self.beta_1 ** self.t) * layer.absolute_gradients[weight_name]) \n",
    "\n",
    "            layer.weights[weight_name] = layer.weights[weight_name] - d\n",
    "\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, layers) -> None:\n",
    "        self.layers = layers\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.forward(*args, **kwds)\n",
    "\n",
    "    def compile(self, loss, optimizer):\n",
    "        self.loss = loss\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Layer):\n",
    "                layer.optimizer = deepcopy(optimizer)\n",
    "\n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        gradient = self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient)\n",
    "\n",
    "        return gradient\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Layer):\n",
    "                layer.update_weights()\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy_score(y_pred, y_true):\n",
    "\n",
    "        pred_labels = np.argmax(y_pred, axis=1)\n",
    "        return np.sum(pred_labels == y_true) / len(y_true)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_batches(X, y, batch_size=32):\n",
    "        batches = []\n",
    "\n",
    "        for i in range(len(y) // batch_size):\n",
    "            start_idx = batch_size * i\n",
    "            end_idx = batch_size * (i + 1)\n",
    "\n",
    "            batches.append([X[start_idx: end_idx], y[start_idx: end_idx]])\n",
    "\n",
    "        # take care of the last batch which might have batch_size less than the specified one\n",
    "        if len(y) % batch_size != 0:\n",
    "            batches.append([X[end_idx:], y[end_idx:]])\n",
    "\n",
    "        return batches\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val, batch_size=32, epochs=10):\n",
    "\n",
    "        # calculate number of classes to pass to the loss function\n",
    "        self.loss.n_classes = len(np.unique(y_train))\n",
    "\n",
    "        train_batches = self.create_batches(X_train, y_train, batch_size=batch_size)\n",
    "        val_batches = self.create_batches(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        num_train_batches = len(train_batches)\n",
    "        num_val_batches = len(val_batches)\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            total_train_loss = 0\n",
    "            total_train_accuracy = 0\n",
    "\n",
    "            ## TRAINING ##\n",
    "            for X, y in train_batches:\n",
    "\n",
    "                preds = self(X)\n",
    "                total_train_loss += self.loss(preds, y)\n",
    "                total_train_accuracy += self.accuracy_score(preds, y)\n",
    "\n",
    "                _ = self.backward()\n",
    "                self.update_weights()\n",
    "\n",
    "            train_loss_per_epoch = total_train_loss / num_train_batches\n",
    "            train_accuracy = total_train_accuracy / num_train_batches\n",
    "\n",
    "            total_val_loss = 0\n",
    "            total_val_accuracy = 0\n",
    "\n",
    "            ## VALIDATION ##\n",
    "            for X_v, y_v in val_batches:\n",
    "                val_preds = self(X_v)\n",
    "                total_val_loss += self.loss(val_preds, y_v)\n",
    "                total_val_accuracy += self.accuracy_score(val_preds, y_v)\n",
    "            \n",
    "            val_loss_per_epoch = total_val_loss / num_val_batches\n",
    "            val_accuracy = total_val_accuracy / num_val_batches\n",
    "            \n",
    "            print(\"Epoch: {} Train Loss: {:0.6f} Train Accuracy: {:0.6f} Val Loss: {:0.6f} Val Accuracy: {:0.6f}\".format(epoch, train_loss_per_epoch, train_accuracy, val_loss_per_epoch, val_accuracy))\n",
    "\n",
    "            self.history.append({\"Epoch\" : epoch, \n",
    "                                    \"Train Loss\": train_loss_per_epoch,\n",
    "                                    \"Train Accuracy\": train_accuracy,\n",
    "                                    \"Val Loss\": val_loss_per_epoch,\n",
    "                                    \"Val Accuracy\": val_accuracy})\n",
    "            \n",
    "            wandb.log({\"epoch\" : epoch, \n",
    "                        \"train_loss\": train_loss_per_epoch,\n",
    "                        \"train_acc\": train_accuracy,\n",
    "                        \"val_loss\": val_loss_per_epoch,\n",
    "                        \"val_acc\": val_accuracy})\n",
    "\n",
    "        print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularizing the Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    if name == \"relu\":\n",
    "        return RelU()\n",
    "    elif name == \"tanh\":\n",
    "        return Tanh()\n",
    "    elif name == \"sigmoid\":\n",
    "        return Sigmoid()\n",
    "\n",
    "def get_optimizer(name, lr):\n",
    "    if name == \"sgd\":\n",
    "        return SGD(lr=lr)\n",
    "    elif name == \"momentum\":\n",
    "        return Momentum(lr=lr)\n",
    "    elif name == \"rmsprop\":\n",
    "        return RMSprop(lr=lr)\n",
    "    elif name == \"adam\":\n",
    "        return Adam(lr=lr)\n",
    "    elif name == \"nadam\":\n",
    "        return Nadam(lr=lr)\n",
    "\n",
    "def create_layers(n_layers, layer_size, activation, weight_decay, init_method):\n",
    "\n",
    "    layers = []\n",
    "    layers.extend([FC(784,layer_size, weight_decay, init_method), get_activation(activation)])\n",
    "    \n",
    "    for _ in range(n_layers):\n",
    "        layers.extend([FC(layer_size, layer_size, weight_decay, init_method), get_activation(activation)])\n",
    "    \n",
    "    layers.append(FC(layer_size, 10, weight_decay, init_method))\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60000 Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(f\"Train samples: {train_images.shape[0]} Test samples: {test_images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utility functions\n",
    "\n",
    "def flatten(arr):\n",
    "    arr = arr.reshape(arr.shape[0], -1)\n",
    "    return arr\n",
    "\n",
    "def plot_labels(data, labels, flatten=False):\n",
    "\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    uniq_labels = np.unique(labels)\n",
    "\n",
    "    fig, ax = plt.subplots(2,5, figsize=(15, 6))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    ax = ax.reshape(-1)\n",
    "\n",
    "    for i, label in enumerate(uniq_labels):\n",
    "\n",
    "        img = data[np.where(labels == label)[0][0]]\n",
    "\n",
    "        ax[i].set_title(class_names[label])\n",
    "        \n",
    "        if flatten:\n",
    "            img = img.reshape(28, 28)\n",
    "\n",
    "        ax[i].imshow(img)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_labels(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = flatten(train_images)\n",
    "test_images = flatten(test_images)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000,), (6000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mbcm7lra\n",
      "Sweep URL: https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"Sweep Test\",\n",
    "  \"method\": \"grid\",\n",
    "  \"parameters\": {\n",
    "        \"epochs\": {\n",
    "            \"values\": [5, 10]\n",
    "        },\n",
    "        \"n_layers\": {\n",
    "            \"values\": [3, 4, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: dyxs57fe with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 3\n",
      "wandb: Currently logged in as: avyay (use `wandb login --relogin` to force relogin)\n",
      "C:\\Users\\rao_a\\Miniconda3\\envs\\PythonCPU\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">floral-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/dyxs57fe\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/dyxs57fe</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235335-dyxs57fe</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dyxs57fe) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19400<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235335-dyxs57fe\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235335-dyxs57fe\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">floral-sweep-1</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/dyxs57fe\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/dyxs57fe</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:dyxs57fe). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">floral-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/dyxs57fe\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/dyxs57fe</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235340-dyxs57fe</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.768298 Train Accuracy: 0.718454 Val Loss: 0.476854 Val Accuracy: 0.828956\n",
      "Epoch: 2 Train Loss: 0.475793 Train Accuracy: 0.828218 Val Loss: 0.437453 Val Accuracy: 0.840758\n",
      "Epoch: 3 Train Loss: 0.425090 Train Accuracy: 0.846508 Val Loss: 0.422563 Val Accuracy: 0.843584\n",
      "Epoch: 4 Train Loss: 0.396270 Train Accuracy: 0.856191 Val Loss: 0.400119 Val Accuracy: 0.851729\n",
      "Epoch: 5 Train Loss: 0.376846 Train Accuracy: 0.863263 Val Loss: 0.380925 Val Accuracy: 0.857879\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1040<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235340-dyxs57fe\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235340-dyxs57fe\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.37685</td></tr><tr><td>train_acc</td><td>0.86326</td></tr><tr><td>val_loss</td><td>0.38092</td></tr><tr><td>val_acc</td><td>0.85788</td></tr><tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1615400638</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▅▄▂▁</td></tr><tr><td>val_acc</td><td>▁▄▅▇█</td></tr><tr><td>_runtime</td><td>▁▃▅▆█</td></tr><tr><td>_timestamp</td><td>▁▃▅▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">floral-sweep-1</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/dyxs57fe\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/dyxs57fe</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: ildv3xr9 with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 4\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glowing-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/ildv3xr9\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/ildv3xr9</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235402-ildv3xr9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.789142 Train Accuracy: 0.704421 Val Loss: 0.496390 Val Accuracy: 0.820811\n",
      "Epoch: 2 Train Loss: 0.471024 Train Accuracy: 0.829254 Val Loss: 0.461163 Val Accuracy: 0.827793\n",
      "Epoch: 3 Train Loss: 0.419552 Train Accuracy: 0.846897 Val Loss: 0.440672 Val Accuracy: 0.836436\n",
      "Epoch: 4 Train Loss: 0.390579 Train Accuracy: 0.857394 Val Loss: 0.440443 Val Accuracy: 0.839096\n",
      "Epoch: 5 Train Loss: 0.369489 Train Accuracy: 0.865392 Val Loss: 0.421357 Val Accuracy: 0.846742\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8600<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235402-ildv3xr9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235402-ildv3xr9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.36949</td></tr><tr><td>train_acc</td><td>0.86539</td></tr><tr><td>val_loss</td><td>0.42136</td></tr><tr><td>val_acc</td><td>0.84674</td></tr><tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1615400654</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▅▃▃▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆█</td></tr><tr><td>_runtime</td><td>▁▃▅▆█</td></tr><tr><td>_timestamp</td><td>▁▃▅▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-2</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/ildv3xr9\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/ildv3xr9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 7siuvidx with config:\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tn_layers: 5\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">unique-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/7siuvidx\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/7siuvidx</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235421-7siuvidx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.911214 Train Accuracy: 0.656194 Val Loss: 0.535093 Val Accuracy: 0.814827\n",
      "Epoch: 2 Train Loss: 0.499350 Train Accuracy: 0.817110 Val Loss: 0.469705 Val Accuracy: 0.828956\n",
      "Epoch: 3 Train Loss: 0.438464 Train Accuracy: 0.840121 Val Loss: 0.452654 Val Accuracy: 0.839096\n",
      "Epoch: 4 Train Loss: 0.405475 Train Accuracy: 0.852229 Val Loss: 0.429550 Val Accuracy: 0.845080\n",
      "Epoch: 5 Train Loss: 0.383424 Train Accuracy: 0.859782 Val Loss: 0.443397 Val Accuracy: 0.837267\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4648<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235421-7siuvidx\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235421-7siuvidx\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.38342</td></tr><tr><td>train_acc</td><td>0.85978</td></tr><tr><td>val_loss</td><td>0.4434</td></tr><tr><td>val_acc</td><td>0.83727</td></tr><tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1615400672</td></tr><tr><td>_step</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▁▂</td></tr><tr><td>val_acc</td><td>▁▄▇█▆</td></tr><tr><td>_runtime</td><td>▁▂▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▅▇█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">unique-sweep-3</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/7siuvidx\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/7siuvidx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: kh9syt6m with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 3\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">crisp-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/kh9syt6m\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/kh9syt6m</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235436-kh9syt6m</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.738137 Train Accuracy: 0.729376 Val Loss: 0.494812 Val Accuracy: 0.829953\n",
      "Epoch: 2 Train Loss: 0.471747 Train Accuracy: 0.829069 Val Loss: 0.438561 Val Accuracy: 0.845911\n",
      "Epoch: 3 Train Loss: 0.419354 Train Accuracy: 0.846397 Val Loss: 0.411195 Val Accuracy: 0.852227\n",
      "Epoch: 4 Train Loss: 0.390480 Train Accuracy: 0.857468 Val Loss: 0.402800 Val Accuracy: 0.851396\n",
      "Epoch: 5 Train Loss: 0.371355 Train Accuracy: 0.865114 Val Loss: 0.398703 Val Accuracy: 0.855053\n",
      "Epoch: 6 Train Loss: 0.356766 Train Accuracy: 0.868835 Val Loss: 0.395170 Val Accuracy: 0.859541\n",
      "Epoch: 7 Train Loss: 0.345045 Train Accuracy: 0.872556 Val Loss: 0.388275 Val Accuracy: 0.865525\n",
      "Epoch: 8 Train Loss: 0.335030 Train Accuracy: 0.876518 Val Loss: 0.379982 Val Accuracy: 0.864860\n",
      "Epoch: 9 Train Loss: 0.326469 Train Accuracy: 0.878536 Val Loss: 0.376264 Val Accuracy: 0.868684\n",
      "Epoch: 10 Train Loss: 0.318246 Train Accuracy: 0.882812 Val Loss: 0.381000 Val Accuracy: 0.868351\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14536<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235436-kh9syt6m\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235436-kh9syt6m\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.31825</td></tr><tr><td>train_acc</td><td>0.88281</td></tr><tr><td>val_loss</td><td>0.381</td></tr><tr><td>val_acc</td><td>0.86835</td></tr><tr><td>_runtime</td><td>18</td></tr><tr><td>_timestamp</td><td>1615400694</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">crisp-sweep-4</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/kh9syt6m\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/kh9syt6m</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: jb863zkb with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 4\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rose-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/jb863zkb\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/jb863zkb</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235459-jb863zkb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.770448 Train Accuracy: 0.716473 Val Loss: 0.481271 Val Accuracy: 0.826795\n",
      "Epoch: 2 Train Loss: 0.484792 Train Accuracy: 0.822997 Val Loss: 0.463583 Val Accuracy: 0.827460\n",
      "Epoch: 3 Train Loss: 0.432991 Train Accuracy: 0.841973 Val Loss: 0.443556 Val Accuracy: 0.834608\n",
      "Epoch: 4 Train Loss: 0.403062 Train Accuracy: 0.852340 Val Loss: 0.415214 Val Accuracy: 0.845745\n",
      "Epoch: 5 Train Loss: 0.382534 Train Accuracy: 0.859893 Val Loss: 0.404023 Val Accuracy: 0.848737\n",
      "Epoch: 6 Train Loss: 0.366540 Train Accuracy: 0.866354 Val Loss: 0.405202 Val Accuracy: 0.851230\n",
      "Epoch: 7 Train Loss: 0.353609 Train Accuracy: 0.870964 Val Loss: 0.412931 Val Accuracy: 0.848737\n",
      "Epoch: 8 Train Loss: 0.342999 Train Accuracy: 0.875222 Val Loss: 0.396952 Val Accuracy: 0.852726\n",
      "Epoch: 9 Train Loss: 0.334706 Train Accuracy: 0.877185 Val Loss: 0.391934 Val Accuracy: 0.853059\n",
      "Epoch: 10 Train Loss: 0.325863 Train Accuracy: 0.880906 Val Loss: 0.378297 Val Accuracy: 0.860372\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17052<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235459-jb863zkb\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235459-jb863zkb\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.32586</td></tr><tr><td>train_acc</td><td>0.88091</td></tr><tr><td>val_loss</td><td>0.3783</td></tr><tr><td>val_acc</td><td>0.86037</td></tr><tr><td>_runtime</td><td>17</td></tr><tr><td>_timestamp</td><td>1615400716</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▂▂▁</td></tr><tr><td>val_acc</td><td>▁▁▃▅▆▆▆▆▆█</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rose-sweep-5</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/jb863zkb\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/jb863zkb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 2y8ju2so with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tn_layers: 5\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">confused-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/avyay/uncategorized\" target=\"_blank\">https://wandb.ai/avyay/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/sweeps/mbcm7lra</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/avyay/uncategorized/runs/2y8ju2so\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/2y8ju2so</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235520-2y8ju2so</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.810174 Train Accuracy: 0.698811 Val Loss: 0.503416 Val Accuracy: 0.822972\n",
      "Epoch: 2 Train Loss: 0.490076 Train Accuracy: 0.820572 Val Loss: 0.455052 Val Accuracy: 0.835771\n",
      "Epoch: 3 Train Loss: 0.432547 Train Accuracy: 0.840640 Val Loss: 0.404811 Val Accuracy: 0.856715\n",
      "Epoch: 4 Train Loss: 0.400104 Train Accuracy: 0.852507 Val Loss: 0.393717 Val Accuracy: 0.859707\n",
      "Epoch: 5 Train Loss: 0.379116 Train Accuracy: 0.860467 Val Loss: 0.383087 Val Accuracy: 0.863032\n",
      "Epoch: 6 Train Loss: 0.361949 Train Accuracy: 0.866669 Val Loss: 0.389227 Val Accuracy: 0.861702\n",
      "Epoch: 7 Train Loss: 0.349031 Train Accuracy: 0.870835 Val Loss: 0.382188 Val Accuracy: 0.865858\n",
      "Epoch: 8 Train Loss: 0.337438 Train Accuracy: 0.875555 Val Loss: 0.386462 Val Accuracy: 0.864195\n",
      "Epoch: 9 Train Loss: 0.329140 Train Accuracy: 0.878332 Val Loss: 0.385880 Val Accuracy: 0.866689\n",
      "Epoch: 10 Train Loss: 0.320581 Train Accuracy: 0.881720 Val Loss: 0.370321 Val Accuracy: 0.868850\n",
      "\n",
      "Model trained successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13260<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235520-2y8ju2so\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\rao_a\\PythonCPU\\Deep Learning\\CS6910-Assignments-1\\Assignment1\\Avyay\\wandb\\run-20210310_235520-2y8ju2so\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.32058</td></tr><tr><td>train_acc</td><td>0.88172</td></tr><tr><td>val_loss</td><td>0.37032</td></tr><tr><td>val_acc</td><td>0.86885</td></tr><tr><td>_runtime</td><td>17</td></tr><tr><td>_timestamp</td><td>1615400738</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▂▂▁</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇█▇██</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">confused-sweep-6</strong>: <a href=\"https://wandb.ai/avyay/uncategorized/runs/2y8ju2so\" target=\"_blank\">https://wandb.ai/avyay/uncategorized/runs/2y8ju2so</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
